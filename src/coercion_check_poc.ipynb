{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4458587f",
   "metadata": {},
   "source": [
    "# Intro\n",
    "## Coercion check\n",
    "\n",
    "In identity verification systems, we need to ensure that people are who they say they are. However, given the range of services that verifying oneself can give access to, it's also important to establish that people verifying themselves are doing so out of their own volition (as opposed to being coerced or incentivised into doing so). A common indicator of this kind of fraud pattern is the presence of multiple people during the verification process.\n",
    "\n",
    "This notebook is meant for proof-of-concepting a sort of a coercion check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01adbe6a",
   "metadata": {},
   "source": [
    "# Setup \n",
    "## Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d1c11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from collections import defaultdict\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3791a1",
   "metadata": {},
   "source": [
    "## GPU\n",
    "Making sure we're using the GPU for any CUDA calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3945ab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current CUDA device: 0\n",
      "CUDA device name: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d00d84",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "## Model initialisation\n",
    "\n",
    "For object detection, The YOLO series of models is really easy to set up and use. Here I am using the pretrained Yolov8 (Ultralytics) model and specifically the medium sized variant (nano, small and large models also exist, with model size leading to better object detection with diminishing returns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c1290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"models/yolov8m.pt\")  # yolov8n.pt, yolov8s.pt or yolov8m.pt for better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e8682",
   "metadata": {},
   "source": [
    "## Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e903bc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "video 1/1 (frame 1/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 53.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 2/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 14.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 3/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 14.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 4/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 5/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 6/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 7/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 8/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 9/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 10/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 11/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 12/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 13/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 14/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 15/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 16/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 17/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 18/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 19/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 20/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 21/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 22/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 23/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 13.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 24/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 25/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 26/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 27/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 28/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 29/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 30/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 31/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 32/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 15.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 33/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 34/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 26.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 35/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 20.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 36/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 37/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 38/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 39/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 40/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 41/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 42/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 43/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 13.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 44/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 19.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 45/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 46/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 47/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 48/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 49/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 50/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 51/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 19.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 52/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 53/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 54/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 19.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 55/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 17.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 56/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 57/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 58/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 19.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 59/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 60/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 61/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 62/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 63/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 64/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 65/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 66/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 67/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 68/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 69/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 70/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 15.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 71/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 72/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 73/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 17.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 74/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 75/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 76/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 77/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 23.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 78/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 79/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 80/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 81/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 82/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 83/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 84/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 85/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 86/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 23.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 87/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 88/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 89/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 13.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 90/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 26.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 91/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 92/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 14.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 93/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 94/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 95/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 96/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 97/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 98/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 13.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 99/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 100/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 101/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 102/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 14.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 103/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 20.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 104/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 20.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 105/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 106/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 17.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 107/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 108/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 20.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 109/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 110/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 17.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 111/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 112/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 113/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 114/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 115/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 21.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 116/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 117/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 118/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 119/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 120/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 121/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 122/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 123/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 124/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 125/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 126/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 127/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 128/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 11.8ms\n",
      "tensor([0., 0.], device='cuda:0')\n",
      "video 1/1 (frame 129/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 11.3ms\n",
      "tensor([ 0.,  0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 130/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 3 persons, 1 cell phone, 25.8ms\n",
      "tensor([ 0., 67.,  0.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 131/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 3 persons, 1 cell phone, 12.8ms\n",
      "tensor([67.,  0.,  0.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 132/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 20.9ms\n",
      "tensor([ 0., 67.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 133/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 24.4ms\n",
      "tensor([ 0., 67.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 134/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 11.3ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 135/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 25.2ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 136/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 remote, 1 cell phone, 11.8ms\n",
      "tensor([ 0., 67., 65.], device='cuda:0')\n",
      "video 1/1 (frame 137/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 17.6ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 138/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 1 cell phone, 25.1ms\n",
      "tensor([ 0., 67., 54.], device='cuda:0')\n",
      "video 1/1 (frame 139/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 1 cell phone, 20.6ms\n",
      "tensor([ 0., 67., 54.], device='cuda:0')\n",
      "video 1/1 (frame 140/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 1 cell phone, 11.7ms\n",
      "tensor([ 0., 67., 54.], device='cuda:0')\n",
      "video 1/1 (frame 141/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 11.3ms\n",
      "tensor([ 0., 67.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 142/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 25.4ms\n",
      "tensor([ 0., 67.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 143/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 3 persons, 1 cell phone, 13.7ms\n",
      "tensor([67.,  0.,  0.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 144/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 15.4ms\n",
      "tensor([ 0., 67.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 145/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 11.9ms\n",
      "tensor([ 0., 67.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 146/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 20.0ms\n",
      "tensor([ 0., 67.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 147/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 cell phone, 16.5ms\n",
      "tensor([ 0., 67.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 148/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 3 persons, 1 cell phone, 24.5ms\n",
      "tensor([67.,  0.,  0.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 149/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 25.2ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 150/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 14.5ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 151/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 14.2ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 152/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 11.2ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 153/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 11.3ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 154/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 13.3ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 155/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 16.9ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 156/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 24.0ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 157/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 11.2ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 158/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 159/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 11.3ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 160/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 1 cell phone, 11.4ms\n",
      "tensor([ 0., 67., 54.], device='cuda:0')\n",
      "video 1/1 (frame 161/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 cell phone, 11.3ms\n",
      "tensor([ 0., 67.], device='cuda:0')\n",
      "video 1/1 (frame 162/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 remote, 1 cell phone, 24.9ms\n",
      "tensor([ 0., 65., 67.], device='cuda:0')\n",
      "video 1/1 (frame 163/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 remote, 1 refrigerator, 11.8ms\n",
      "tensor([ 0., 65., 72.], device='cuda:0')\n",
      "video 1/1 (frame 164/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 remote, 1 cell phone, 25.1ms\n",
      "tensor([ 0., 67., 65.], device='cuda:0')\n",
      "video 1/1 (frame 165/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 remote, 24.9ms\n",
      "tensor([ 0., 65.], device='cuda:0')\n",
      "video 1/1 (frame 166/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.6ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 167/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.2ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 168/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 169/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 donut, 12.0ms\n",
      "tensor([ 0., 54.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 170/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 donut, 11.5ms\n",
      "tensor([ 0., 54.,  0.], device='cuda:0')\n",
      "video 1/1 (frame 171/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 11.6ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 172/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 11.3ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 173/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 174/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.2ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 175/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 176/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 177/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 178/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 179/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 180/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 181/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 19.7ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 182/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 26.1ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 183/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 22.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 184/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 185/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 186/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 24.7ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 187/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 15.9ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 188/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.4ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 189/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 16.2ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 190/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 1 teddy bear, 11.5ms\n",
      "tensor([ 0., 72., 77.], device='cuda:0')\n",
      "video 1/1 (frame 191/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.5ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 192/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 14.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 193/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 microwave, 1 refrigerator, 11.5ms\n",
      "tensor([ 0., 72., 68.], device='cuda:0')\n",
      "video 1/1 (frame 194/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 195/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 25.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 196/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 197/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 198/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 199/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 200/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 201/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 17.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 202/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 23.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 203/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 22.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 204/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 12.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 205/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 16.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 206/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.2ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 207/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.6ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 208/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 209/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 15.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 210/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.9ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 211/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 212/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 11.1ms\n",
      "tensor([0., 0.], device='cuda:0')\n",
      "video 1/1 (frame 213/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 2 persons, 1 book, 14.1ms\n",
      "tensor([ 0.,  0., 73.], device='cuda:0')\n",
      "video 1/1 (frame 214/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 microwave, 1 refrigerator, 21.1ms\n",
      "tensor([ 0., 68., 72.], device='cuda:0')\n",
      "video 1/1 (frame 215/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 216/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 10.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 217/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 218/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 17.8ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 219/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.3ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 220/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 221/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 16.9ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 222/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.6ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 223/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 16.4ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 224/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 29.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 225/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 12.2ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 226/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 11.4ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 227/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 1 refrigerator, 25.6ms\n",
      "tensor([ 0., 72., 54.], device='cuda:0')\n",
      "video 1/1 (frame 228/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 11.7ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 229/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 11.5ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 230/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 1 refrigerator, 11.1ms\n",
      "tensor([ 0., 54., 72.], device='cuda:0')\n",
      "video 1/1 (frame 231/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.8ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 232/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 14.3ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 233/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 donut, 18.8ms\n",
      "tensor([ 0., 54.], device='cuda:0')\n",
      "video 1/1 (frame 234/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 14.0ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 235/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 236/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.4ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 237/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 22.8ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 238/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.2ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 239/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 14.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 240/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 20.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 241/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 242/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 14.7ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 243/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 244/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.4ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 245/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 10.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 246/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 18.3ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 247/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 24.1ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 248/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 19.9ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 249/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 11.5ms\n",
      "tensor([0.], device='cuda:0')\n",
      "video 1/1 (frame 250/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 11.4ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 251/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 2 refrigerators, 24.5ms\n",
      "tensor([ 0., 72., 72.], device='cuda:0')\n",
      "video 1/1 (frame 252/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 25.3ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "video 1/1 (frame 253/253) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff1.mp4: 384x640 1 person, 1 refrigerator, 15.0ms\n",
      "tensor([ 0., 72.], device='cuda:0')\n",
      "Speed: 1.2ms preprocess, 15.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(\"videos/veriff1.mp4\", stream=True)\n",
    "for result in results:\n",
    "    print(result.boxes.cls)  # Class IDs (e.g. 0 for \"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa741c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/253 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 2.4ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/253 [00:00<00:13, 18.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.7ms\n",
      "Speed: 1.9ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.9ms\n",
      "Speed: 1.4ms preprocess, 24.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 5/253 [00:00<00:12, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 24.7ms\n",
      "Speed: 1.2ms preprocess, 24.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 8/253 [00:00<00:11, 21.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.5ms\n",
      "Speed: 1.1ms preprocess, 16.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 11/253 [00:00<00:10, 22.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.4ms\n",
      "Speed: 1.2ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 14/253 [00:00<00:09, 23.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.5ms\n",
      "Speed: 1.1ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 17/253 [00:00<00:09, 24.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.7ms\n",
      "Speed: 1.1ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 23.9ms\n",
      "Speed: 1.2ms preprocess, 23.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 20/253 [00:00<00:09, 24.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.0ms\n",
      "Speed: 1.1ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 23/253 [00:00<00:09, 24.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.4ms\n",
      "Speed: 1.2ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 26/253 [00:01<00:09, 24.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 13.6ms\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 1.2ms preprocess, 15.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|        | 29/253 [00:01<00:08, 25.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.6ms\n",
      "Speed: 1.8ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 1.4ms preprocess, 15.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 32/253 [00:01<00:08, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 1.2ms preprocess, 17.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.5ms\n",
      "Speed: 1.1ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 35/253 [00:01<00:08, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 1.2ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.2ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 38/253 [00:01<00:08, 25.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 41/253 [00:01<00:08, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.1ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 44/253 [00:01<00:08, 25.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 1.1ms preprocess, 15.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 1.1ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 47/253 [00:01<00:08, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 1.2ms preprocess, 16.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 1.8ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 50/253 [00:02<00:08, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.5ms\n",
      "Speed: 1.2ms preprocess, 13.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 53/253 [00:02<00:07, 25.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 13.3ms\n",
      "Speed: 1.2ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 56/253 [00:02<00:07, 25.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 1.2ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 59/253 [00:02<00:07, 25.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 1.3ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 1.1ms preprocess, 15.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 62/253 [00:02<00:07, 25.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 14.4ms\n",
      "Speed: 1.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.7ms\n",
      "Speed: 1.1ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 65/253 [00:02<00:07, 25.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 13.6ms\n",
      "Speed: 1.5ms preprocess, 13.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.4ms\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 68/253 [00:02<00:07, 25.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.9ms\n",
      "Speed: 1.8ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 71/253 [00:02<00:07, 25.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 74/253 [00:02<00:06, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.1ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 77/253 [00:03<00:06, 26.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.1ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.6ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 1.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 80/253 [00:03<00:06, 26.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 1.3ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 83/253 [00:03<00:06, 25.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.8ms\n",
      "Speed: 2.6ms preprocess, 28.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 86/253 [00:03<00:06, 24.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 89/253 [00:03<00:06, 25.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.2ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 92/253 [00:03<00:06, 25.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 1.2ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 95/253 [00:03<00:06, 25.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.6ms\n",
      "Speed: 1.2ms preprocess, 12.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 1.2ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 1.2ms preprocess, 16.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 98/253 [00:03<00:06, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.1ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 1.2ms preprocess, 15.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 101/253 [00:04<00:05, 25.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 1.3ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 104/253 [00:04<00:05, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 1.5ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 107/253 [00:04<00:05, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 110/253 [00:04<00:05, 25.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.7ms\n",
      "Speed: 1.3ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.2ms\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.3ms\n",
      "Speed: 1.6ms preprocess, 12.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 113/253 [00:04<00:05, 25.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 14.7ms\n",
      "Speed: 1.3ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 116/253 [00:04<00:05, 25.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 1.6ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 1.5ms preprocess, 15.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 119/253 [00:04<00:05, 25.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 1.9ms preprocess, 15.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.1ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 122/253 [00:04<00:05, 25.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.6ms\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 125/253 [00:04<00:05, 25.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 10.9ms\n",
      "Speed: 1.2ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 128/253 [00:05<00:04, 25.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 13.5ms\n",
      "Speed: 1.1ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 131/253 [00:05<00:04, 24.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 12.3ms\n",
      "Speed: 1.6ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 134/253 [00:05<00:04, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 137/253 [00:05<00:04, 24.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 donut, 1 cell phone, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 1 cell phone, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 1 cell phone, 14.4ms\n",
      "Speed: 1.4ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 140/253 [00:05<00:04, 24.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 15.4ms\n",
      "Speed: 1.2ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 143/253 [00:05<00:04, 23.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 15.7ms\n",
      "Speed: 1.2ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 146/253 [00:05<00:04, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 12.0ms\n",
      "Speed: 1.2ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 149/253 [00:05<00:04, 23.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 14.5ms\n",
      "Speed: 1.8ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 152/253 [00:06<00:04, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.4ms\n",
      "Speed: 1.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|   | 155/253 [00:06<00:04, 23.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 15.4ms\n",
      "Speed: 1.3ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 22.3ms\n",
      "Speed: 1.2ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 23.5ms\n",
      "Speed: 1.3ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 158/253 [00:06<00:04, 22.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 22.2ms\n",
      "Speed: 1.3ms preprocess, 22.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 1 cell phone, 23.9ms\n",
      "Speed: 1.3ms preprocess, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 23.6ms\n",
      "Speed: 1.3ms preprocess, 23.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 161/253 [00:06<00:04, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 19.0ms\n",
      "Speed: 1.5ms preprocess, 19.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 refrigerator, 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 25.6ms\n",
      "Speed: 1.3ms preprocess, 25.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 164/253 [00:06<00:04, 19.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 remote, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 24.9ms\n",
      "Speed: 1.4ms preprocess, 24.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 22.0ms\n",
      "Speed: 1.2ms preprocess, 22.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 167/253 [00:06<00:04, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 21.0ms\n",
      "Speed: 1.2ms preprocess, 21.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 donut, 11.3ms\n",
      "Speed: 1.1ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 170/253 [00:07<00:04, 20.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 donut, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 173/253 [00:07<00:03, 21.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 176/253 [00:07<00:03, 22.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 1.3ms preprocess, 15.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 179/253 [00:07<00:03, 23.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 12.1ms\n",
      "Speed: 1.1ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 182/253 [00:07<00:02, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 1.6ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 185/253 [00:07<00:02, 24.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 188/253 [00:07<00:02, 24.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 1 teddy bear, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 15.9ms\n",
      "Speed: 1.9ms preprocess, 15.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 191/253 [00:07<00:02, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 14.1ms\n",
      "Speed: 1.1ms preprocess, 14.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 refrigerator, 25.7ms\n",
      "Speed: 1.2ms preprocess, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 194/253 [00:08<00:02, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.1ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 197/253 [00:08<00:02, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 24.9ms\n",
      "Speed: 1.2ms preprocess, 24.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 200/253 [00:08<00:02, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.1ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 203/253 [00:08<00:02, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 206/253 [00:08<00:01, 25.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 18.6ms\n",
      "Speed: 1.2ms preprocess, 18.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.6ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 209/253 [00:08<00:01, 25.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.3ms\n",
      "Speed: 1.1ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 212/253 [00:08<00:01, 25.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 12.1ms\n",
      "Speed: 1.1ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 microwave, 1 refrigerator, 11.4ms\n",
      "Speed: 1.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21.7ms\n",
      "Speed: 1.4ms preprocess, 21.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 215/253 [00:08<00:01, 24.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 20.8ms\n",
      "Speed: 2.2ms preprocess, 20.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 218/253 [00:08<00:01, 24.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 221/253 [00:09<00:01, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 22.6ms\n",
      "Speed: 1.3ms preprocess, 22.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 12.6ms\n",
      "Speed: 1.1ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 224/253 [00:09<00:01, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 donut, 11.6ms\n",
      "Speed: 1.1ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 1 refrigerator, 11.4ms\n",
      "Speed: 1.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 227/253 [00:09<00:01, 24.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 donut, 21.6ms\n",
      "Speed: 1.2ms preprocess, 21.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 1 refrigerator, 24.2ms\n",
      "Speed: 1.2ms preprocess, 24.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 230/253 [00:09<00:01, 21.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 20.3ms\n",
      "Speed: 1.3ms preprocess, 20.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 donut, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 233/253 [00:09<00:00, 21.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 10.8ms\n",
      "Speed: 1.2ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 236/253 [00:09<00:00, 22.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.0ms\n",
      "Speed: 1.1ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.1ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 239/253 [00:09<00:00, 24.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.1ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.1ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 242/253 [00:09<00:00, 25.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.1ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 245/253 [00:10<00:00, 25.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.1ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.8ms\n",
      "Speed: 1.1ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 248/253 [00:10<00:00, 26.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 19.4ms\n",
      "Speed: 1.2ms preprocess, 19.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.0ms\n",
      "Speed: 1.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 refrigerators, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 251/253 [00:10<00:00, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 refrigerator, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 253/253 [00:10<00:00, 24.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processed and saved as videos/veriff1_annotated.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_video_with_boxes(input_path, output_path, model):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Create video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Process each frame\n",
    "    for _ in tqdm(range(total_frames)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "        \n",
    "        # Get the first result (only one image was processed)\n",
    "        result = results[0]\n",
    "        \n",
    "        # Draw bounding boxes and labels on the frame\n",
    "        for box in result.boxes:\n",
    "            # Get box coordinates (convert to integers for drawing)\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            \n",
    "            # Get class and confidence\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            \n",
    "            # Get class name (you can customize this based on your model)\n",
    "            class_names = model.names\n",
    "            cls_name = class_names[cls_id]\n",
    "            \n",
    "            # Only annotate people (class 0) if you want to focus on coercion detection\n",
    "            if cls_id == 0:  # person class\n",
    "                # Draw rectangle\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Add label with confidence\n",
    "                label = f\"{cls_name}: {conf:.2f}\"\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # Write the frame to output video\n",
    "        out.write(frame)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    return output_path\n",
    "\n",
    "# Process the video and create a new one with bounding boxes\n",
    "output_file = \"videos/veriff1_annotated.mp4\"\n",
    "processed_video = process_video_with_boxes(\"videos/veriff1.mp4\", output_file, model)\n",
    "\n",
    "print(f\"Video processed and saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d68dea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/396 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 16.7ms\n",
      "Speed: 2.6ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.2ms\n",
      "Speed: 1.6ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/396 [00:00<00:22, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 dog, 11.8ms\n",
      "Speed: 1.6ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 5/396 [00:00<00:18, 20.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 12.8ms\n",
      "Speed: 1.6ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 13.8ms\n",
      "Speed: 2.2ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 13.9ms\n",
      "Speed: 2.0ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 8/396 [00:00<00:17, 21.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 11/396 [00:00<00:16, 23.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 dog, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.0ms\n",
      "Speed: 1.9ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 14/396 [00:00<00:15, 24.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 16.5ms\n",
      "Speed: 1.8ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 14.7ms\n",
      "Speed: 1.4ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 17/396 [00:00<00:15, 24.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 16.1ms\n",
      "Speed: 1.5ms preprocess, 16.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 12.8ms\n",
      "Speed: 1.3ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 22.9ms\n",
      "Speed: 2.4ms preprocess, 22.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 20/396 [00:00<00:16, 23.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 dog, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 19.0ms\n",
      "Speed: 1.3ms preprocess, 19.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 remote, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 23/396 [00:00<00:15, 23.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 remote, 13.5ms\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 26/396 [00:01<00:15, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 remote, 1 book, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 29/396 [00:01<00:15, 23.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 remote, 1 book, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 32/396 [00:01<00:15, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 donut, 1 book, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 donut, 1 book, 23.1ms\n",
      "Speed: 1.4ms preprocess, 23.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cat, 1 dog, 1 donut, 1 book, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 35/396 [00:01<00:16, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 38/396 [00:01<00:15, 22.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 41/396 [00:01<00:15, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.7ms\n",
      "Speed: 1.6ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 44/396 [00:01<00:15, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 carrot, 1 book, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 donut, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 47/396 [00:02<00:14, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 19.1ms\n",
      "Speed: 1.4ms preprocess, 19.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 20.9ms\n",
      "Speed: 1.6ms preprocess, 20.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 50/396 [00:02<00:15, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 donut, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 53/396 [00:02<00:14, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 donut, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 15.0ms\n",
      "Speed: 1.4ms preprocess, 15.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 56/396 [00:02<00:14, 23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 donut, 1 book, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.4ms\n",
      "Speed: 1.7ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 59/396 [00:02<00:14, 24.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 bottle, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 62/396 [00:02<00:13, 24.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 remote, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.5ms\n",
      "Speed: 1.5ms preprocess, 14.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 65/396 [00:02<00:13, 24.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 bottle, 1 remote, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 68/396 [00:02<00:13, 24.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 bottle, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 11.7ms\n",
      "Speed: 1.6ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 13.2ms\n",
      "Speed: 1.6ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 71/396 [00:03<00:13, 24.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 74/396 [00:03<00:12, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 77/396 [00:03<00:12, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 bottle, 1 book, 15.7ms\n",
      "Speed: 1.4ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 1 book, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 80/396 [00:03<00:13, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 14.3ms\n",
      "Speed: 1.6ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 83/396 [00:03<00:13, 23.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 11.9ms\n",
      "Speed: 1.6ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 86/396 [00:03<00:12, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 23.1ms\n",
      "Speed: 1.4ms preprocess, 23.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 book, 22.8ms\n",
      "Speed: 1.4ms preprocess, 22.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 89/396 [00:03<00:14, 21.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 22.4ms\n",
      "Speed: 1.8ms preprocess, 22.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 19.9ms\n",
      "Speed: 1.6ms preprocess, 19.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 92/396 [00:03<00:14, 20.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 20.9ms\n",
      "Speed: 1.4ms preprocess, 20.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 20.7ms\n",
      "Speed: 1.7ms preprocess, 20.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 95/396 [00:04<00:14, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 17.7ms\n",
      "Speed: 1.4ms preprocess, 17.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21.3ms\n",
      "Speed: 1.4ms preprocess, 21.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 98/396 [00:04<00:14, 20.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 20.5ms\n",
      "Speed: 1.4ms preprocess, 20.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 books, 21.4ms\n",
      "Speed: 1.4ms preprocess, 21.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 20.7ms\n",
      "Speed: 1.4ms preprocess, 20.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 101/396 [00:04<00:14, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 104/396 [00:04<00:13, 21.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 15.5ms\n",
      "Speed: 1.5ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 107/396 [00:04<00:13, 21.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.1ms\n",
      "Speed: 1.3ms preprocess, 13.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 110/396 [00:04<00:12, 23.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 refrigerator, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 113/396 [00:04<00:11, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 refrigerator, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 refrigerator, 16.1ms\n",
      "Speed: 1.9ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 refrigerator, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 116/396 [00:05<00:12, 23.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 refrigerator, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 refrigerator, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 refrigerator, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 119/396 [00:05<00:11, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 2 refrigerators, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 14.1ms\n",
      "Speed: 1.3ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 122/396 [00:05<00:11, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 125/396 [00:05<00:11, 24.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 13.2ms\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 128/396 [00:05<00:10, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 131/396 [00:05<00:10, 24.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 16.4ms\n",
      "Speed: 1.3ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 134/396 [00:05<00:10, 25.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 137/396 [00:05<00:10, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 13.2ms\n",
      "Speed: 1.3ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 140/396 [00:05<00:10, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 143/396 [00:06<00:10, 25.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 refrigerator, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 146/396 [00:06<00:09, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 refrigerator, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 149/396 [00:06<00:09, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 152/396 [00:06<00:09, 25.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 155/396 [00:06<00:09, 25.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 10.8ms\n",
      "Speed: 1.3ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 158/396 [00:06<00:09, 25.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 161/396 [00:06<00:09, 25.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 1 book, 14.3ms\n",
      "Speed: 1.3ms preprocess, 14.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 book, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|     | 164/396 [00:06<00:09, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 167/396 [00:07<00:09, 25.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 170/396 [00:07<00:08, 25.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 book, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 16.1ms\n",
      "Speed: 1.7ms preprocess, 16.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 173/396 [00:07<00:09, 24.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.5ms\n",
      "Speed: 1.4ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 176/396 [00:07<00:08, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 15.5ms\n",
      "Speed: 1.4ms preprocess, 15.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 179/396 [00:07<00:09, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 15.3ms\n",
      "Speed: 1.9ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 182/396 [00:07<00:09, 23.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 10.9ms\n",
      "Speed: 1.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 185/396 [00:07<00:08, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 refrigerator, 1 book, 14.2ms\n",
      "Speed: 1.7ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 188/396 [00:07<00:08, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 refrigerator, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.9ms\n",
      "Speed: 1.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 191/396 [00:08<00:08, 23.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 book, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.5ms\n",
      "Speed: 2.1ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 13.5ms\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 194/396 [00:08<00:08, 24.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 18.2ms\n",
      "Speed: 1.7ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 18.3ms\n",
      "Speed: 1.7ms preprocess, 18.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 197/396 [00:08<00:08, 22.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 14.3ms\n",
      "Speed: 1.4ms preprocess, 14.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 14.1ms\n",
      "Speed: 1.6ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 200/396 [00:08<00:09, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 13.4ms\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|    | 203/396 [00:08<00:09, 20.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 13.2ms\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 13.2ms\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12.9ms\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 206/396 [00:08<00:09, 20.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 1 book, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 book, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 book, 19.3ms\n",
      "Speed: 1.5ms preprocess, 19.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 209/396 [00:08<00:09, 20.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 1 book, 14.0ms\n",
      "Speed: 2.3ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 book, 12.5ms\n",
      "Speed: 1.8ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 book, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 212/396 [00:09<00:08, 20.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 22.4ms\n",
      "Speed: 1.4ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 215/396 [00:09<00:08, 20.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 16.2ms\n",
      "Speed: 1.3ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 218/396 [00:09<00:08, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 17.0ms\n",
      "Speed: 1.6ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 221/396 [00:09<00:07, 22.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 23.5ms\n",
      "Speed: 1.4ms preprocess, 23.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 224/396 [00:09<00:08, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 book, 18.4ms\n",
      "Speed: 2.0ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 227/396 [00:09<00:07, 21.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 230/396 [00:09<00:07, 22.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 16.2ms\n",
      "Speed: 1.4ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 233/396 [00:10<00:07, 22.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 22.7ms\n",
      "Speed: 2.0ms preprocess, 22.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.3ms\n",
      "Speed: 2.1ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 22.3ms\n",
      "Speed: 1.6ms preprocess, 22.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 236/396 [00:10<00:07, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 22.1ms\n",
      "Speed: 1.4ms preprocess, 22.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 239/396 [00:10<00:07, 20.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 16.3ms\n",
      "Speed: 1.4ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 15.9ms\n",
      "Speed: 1.4ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 242/396 [00:10<00:07, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 2 dogs, 1 book, 12.0ms\n",
      "Speed: 1.5ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.3ms\n",
      "Speed: 2.1ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 245/396 [00:10<00:07, 21.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 1 book, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 248/396 [00:10<00:06, 21.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 1 book, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 251/396 [00:10<00:06, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 22.1ms\n",
      "Speed: 1.4ms preprocess, 22.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 254/396 [00:11<00:06, 21.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 book, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 257/396 [00:11<00:06, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.9ms\n",
      "Speed: 1.6ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.5ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 260/396 [00:11<00:06, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.2ms\n",
      "Speed: 1.6ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 263/396 [00:11<00:06, 21.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 book, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 266/396 [00:11<00:05, 22.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 17.9ms\n",
      "Speed: 1.5ms preprocess, 17.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 269/396 [00:11<00:06, 21.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 21.8ms\n",
      "Speed: 2.0ms preprocess, 21.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 18.1ms\n",
      "Speed: 1.4ms preprocess, 18.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 272/396 [00:11<00:06, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 13.3ms\n",
      "Speed: 1.4ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 book, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 275/396 [00:12<00:05, 21.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 22.8ms\n",
      "Speed: 1.4ms preprocess, 22.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 1 book, 21.4ms\n",
      "Speed: 1.5ms preprocess, 21.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 278/396 [00:12<00:05, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 24.4ms\n",
      "Speed: 1.4ms preprocess, 24.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 bottle, 18.9ms\n",
      "Speed: 1.4ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 21.3ms\n",
      "Speed: 1.5ms preprocess, 21.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 281/396 [00:12<00:05, 20.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 bottle, 20.6ms\n",
      "Speed: 1.4ms preprocess, 20.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 bottle, 21.2ms\n",
      "Speed: 1.5ms preprocess, 21.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 22.9ms\n",
      "Speed: 1.9ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 284/396 [00:12<00:05, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 22.4ms\n",
      "Speed: 1.8ms preprocess, 22.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 19.8ms\n",
      "Speed: 1.4ms preprocess, 19.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 18.6ms\n",
      "Speed: 1.6ms preprocess, 18.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 287/396 [00:12<00:05, 19.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 18.2ms\n",
      "Speed: 1.4ms preprocess, 18.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 21.7ms\n",
      "Speed: 1.5ms preprocess, 21.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.2ms\n",
      "Speed: 2.6ms preprocess, 25.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 290/396 [00:12<00:05, 20.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 17.6ms\n",
      "Speed: 1.4ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 293/396 [00:12<00:04, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 book, 15.3ms\n",
      "Speed: 1.3ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 remote, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 296/396 [00:13<00:04, 21.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 remote, 1 book, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 299/396 [00:13<00:04, 22.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 23.5ms\n",
      "Speed: 1.4ms preprocess, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 302/396 [00:13<00:04, 22.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 305/396 [00:13<00:03, 22.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 12.8ms\n",
      "Speed: 1.4ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 308/396 [00:13<00:03, 23.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 13.0ms\n",
      "Speed: 1.3ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 19.9ms\n",
      "Speed: 1.8ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 311/396 [00:13<00:03, 23.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 bottle, 11.4ms\n",
      "Speed: 2.1ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 bottle, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 314/396 [00:13<00:03, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 317/396 [00:13<00:03, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 26.0ms\n",
      "Speed: 1.5ms preprocess, 26.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 320/396 [00:14<00:03, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 323/396 [00:14<00:03, 23.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 326/396 [00:14<00:02, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 22.4ms\n",
      "Speed: 1.4ms preprocess, 22.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 329/396 [00:14<00:03, 22.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 20.6ms\n",
      "Speed: 1.5ms preprocess, 20.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 332/396 [00:14<00:02, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 15.2ms\n",
      "Speed: 1.3ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 13.6ms\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 335/396 [00:14<00:02, 22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 14.8ms\n",
      "Speed: 1.4ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 15.2ms\n",
      "Speed: 1.4ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 338/396 [00:14<00:02, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 13.5ms\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 bottle, 1 book, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 341/396 [00:14<00:02, 23.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 14.1ms\n",
      "Speed: 1.3ms preprocess, 14.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 23.5ms\n",
      "Speed: 1.9ms preprocess, 23.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 344/396 [00:15<00:02, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 15.5ms\n",
      "Speed: 1.3ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.0ms\n",
      "Speed: 1.5ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 347/396 [00:15<00:02, 22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.1ms\n",
      "Speed: 1.5ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 dogs, 1 book, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 16.0ms\n",
      "Speed: 1.4ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 350/396 [00:15<00:01, 23.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 18.0ms\n",
      "Speed: 1.7ms preprocess, 18.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 15.7ms\n",
      "Speed: 1.7ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 353/396 [00:15<00:01, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 12.5ms\n",
      "Speed: 1.6ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 356/396 [00:15<00:01, 22.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 14.4ms\n",
      "Speed: 1.6ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 359/396 [00:15<00:01, 23.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.1ms\n",
      "Speed: 1.4ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 362/396 [00:15<00:01, 24.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 book, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 donut, 1 book, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 365/396 [00:15<00:01, 24.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 dog, 1 book, 16.5ms\n",
      "Speed: 1.3ms preprocess, 16.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 dog, 1 book, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 book, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 368/396 [00:16<00:01, 23.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 15.7ms\n",
      "Speed: 1.3ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cat, 1 dog, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 13.1ms\n",
      "Speed: 1.4ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 371/396 [00:16<00:01, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 remote, 13.7ms\n",
      "Speed: 1.4ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 remote, 11.1ms\n",
      "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 374/396 [00:16<00:00, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 12.9ms\n",
      "Speed: 1.5ms preprocess, 12.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 377/396 [00:16<00:00, 24.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 10.7ms\n",
      "Speed: 1.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.9ms\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.0ms\n",
      "Speed: 1.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 380/396 [00:16<00:00, 24.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 dog, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 15.2ms\n",
      "Speed: 1.4ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 383/396 [00:16<00:00, 24.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 13.2ms\n",
      "Speed: 1.5ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 14.3ms\n",
      "Speed: 1.3ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 386/396 [00:16<00:00, 24.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 14.8ms\n",
      "Speed: 1.3ms preprocess, 14.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 11.0ms\n",
      "Speed: 1.6ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 389/396 [00:16<00:00, 25.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 1 dog, 14.9ms\n",
      "Speed: 1.3ms preprocess, 14.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 14.7ms\n",
      "Speed: 1.5ms preprocess, 14.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 11.0ms\n",
      "Speed: 1.4ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 392/396 [00:17<00:00, 24.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 dog, 12.7ms\n",
      "Speed: 1.3ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 15.1ms\n",
      "Speed: 1.3ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 395/396 [00:17<00:00, 24.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 dog, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 396/396 [00:17<00:00, 22.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processed and saved as videos/veriff18_annotated.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process the video and create a new one with bounding boxes\n",
    "output_file = \"videos/veriff18_annotated.mp4\"\n",
    "processed_video = process_video_with_boxes(\"videos/veriff18.mp4\", output_file, model)\n",
    "\n",
    "print(f\"Video processed and saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df0e0fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/312 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.6ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/312 [00:00<00:16, 18.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 1.5ms preprocess, 15.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.5ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.8ms\n",
      "Speed: 1.2ms preprocess, 18.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 5/312 [00:00<00:14, 21.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 1.2ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 8/312 [00:00<00:12, 23.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 14.9ms\n",
      "Speed: 1.8ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 11/312 [00:00<00:12, 24.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 14/312 [00:00<00:11, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 1.2ms preprocess, 14.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 17/312 [00:00<00:11, 24.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 20/312 [00:00<00:11, 24.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.1ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 23/312 [00:00<00:11, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.2ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 26/312 [00:01<00:11, 25.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 13.5ms\n",
      "Speed: 1.2ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 29/312 [00:01<00:11, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.2ms\n",
      "Speed: 1.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 12.1ms\n",
      "Speed: 1.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 laptop, 1 cell phone, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 32/312 [00:01<00:11, 24.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 book, 14.6ms\n",
      "Speed: 1.6ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 35/312 [00:01<00:11, 24.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 38/312 [00:01<00:11, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 15.3ms\n",
      "Speed: 1.2ms preprocess, 15.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 10.8ms\n",
      "Speed: 1.4ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 41/312 [00:01<00:11, 24.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 1.5ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.3ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 44/312 [00:01<00:11, 24.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.5ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.9ms\n",
      "Speed: 1.2ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.8ms\n",
      "Speed: 1.5ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 47/312 [00:01<00:10, 24.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 20.3ms\n",
      "Speed: 1.4ms preprocess, 20.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 cell phone, 15.0ms\n",
      "Speed: 1.2ms preprocess, 15.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 50/312 [00:02<00:10, 23.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 15.2ms\n",
      "Speed: 1.2ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 53/312 [00:02<00:10, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 14.6ms\n",
      "Speed: 1.6ms preprocess, 14.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.0ms\n",
      "Speed: 1.2ms preprocess, 11.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 56/312 [00:02<00:10, 23.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 13.1ms\n",
      "Speed: 1.4ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.8ms\n",
      "Speed: 1.5ms preprocess, 11.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 59/312 [00:02<00:10, 23.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 62/312 [00:02<00:10, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 14.3ms\n",
      "Speed: 1.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.7ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 65/312 [00:02<00:10, 23.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.3ms\n",
      "Speed: 1.5ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 68/312 [00:02<00:10, 24.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 71/312 [00:02<00:09, 24.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 74/312 [00:03<00:09, 24.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.4ms\n",
      "Speed: 1.3ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 77/312 [00:03<00:09, 24.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 80/312 [00:03<00:09, 23.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 14.9ms\n",
      "Speed: 1.4ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 83/312 [00:03<00:09, 23.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.1ms\n",
      "Speed: 1.2ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 14.7ms\n",
      "Speed: 1.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 86/312 [00:03<00:09, 23.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 10.9ms\n",
      "Speed: 1.3ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 16.1ms\n",
      "Speed: 1.3ms preprocess, 16.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.8ms\n",
      "Speed: 1.1ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 89/312 [00:03<00:09, 23.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 12.1ms\n",
      "Speed: 1.2ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.1ms\n",
      "Speed: 1.3ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 92/312 [00:03<00:09, 22.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 book, 19.3ms\n",
      "Speed: 1.3ms preprocess, 19.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 book, 14.5ms\n",
      "Speed: 1.2ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 95/312 [00:03<00:09, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cup, 12.9ms\n",
      "Speed: 1.3ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cup, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cup, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|      | 98/312 [00:04<00:09, 23.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.2ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.4ms\n",
      "Speed: 1.7ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 101/312 [00:04<00:09, 23.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.8ms\n",
      "Speed: 1.4ms preprocess, 16.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.4ms\n",
      "Speed: 2.1ms preprocess, 17.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 104/312 [00:04<00:08, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.2ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 107/312 [00:04<00:08, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 13.1ms\n",
      "Speed: 1.4ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 1.2ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 110/312 [00:04<00:08, 24.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.8ms\n",
      "Speed: 1.2ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 113/312 [00:04<00:07, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.4ms\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 116/312 [00:04<00:07, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 1.3ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 119/312 [00:04<00:07, 25.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 122/312 [00:05<00:07, 26.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.5ms\n",
      "Speed: 1.3ms preprocess, 18.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 125/312 [00:05<00:07, 26.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 128/312 [00:05<00:07, 25.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 131/312 [00:05<00:06, 25.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 17.2ms\n",
      "Speed: 1.4ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 134/312 [00:05<00:06, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 13.4ms\n",
      "Speed: 1.3ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 137/312 [00:05<00:06, 25.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.1ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 140/312 [00:05<00:06, 25.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.5ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 143/312 [00:05<00:06, 25.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 10.8ms\n",
      "Speed: 1.2ms preprocess, 10.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.3ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 22.1ms\n",
      "Speed: 1.3ms preprocess, 22.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 146/312 [00:05<00:06, 25.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.2ms\n",
      "Speed: 1.1ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 149/312 [00:06<00:06, 24.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.9ms\n",
      "Speed: 1.2ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.3ms\n",
      "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 152/312 [00:06<00:06, 25.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.8ms\n",
      "Speed: 1.2ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 11.5ms\n",
      "Speed: 1.3ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 155/312 [00:06<00:06, 24.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 laptop, 13.6ms\n",
      "Speed: 1.7ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 158/312 [00:06<00:06, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 laptop, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 11.8ms\n",
      "Speed: 1.3ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 161/312 [00:06<00:06, 24.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 164/312 [00:06<00:06, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.1ms\n",
      "Speed: 1.3ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.8ms\n",
      "Speed: 1.2ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 167/312 [00:06<00:05, 24.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 19.8ms\n",
      "Speed: 1.3ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "Speed: 1.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 170/312 [00:06<00:05, 24.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.5ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.3ms\n",
      "Speed: 1.3ms preprocess, 11.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 173/312 [00:07<00:05, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 14.7ms\n",
      "Speed: 1.2ms preprocess, 14.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 176/312 [00:07<00:05, 24.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.6ms\n",
      "Speed: 1.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "Speed: 1.2ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 179/312 [00:07<00:05, 24.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 24.4ms\n",
      "Speed: 1.4ms preprocess, 24.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 pizza, 1 cell phone, 11.5ms\n",
      "Speed: 1.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.1ms\n",
      "Speed: 1.1ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 182/312 [00:07<00:05, 23.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "Speed: 1.2ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 185/312 [00:07<00:05, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 13.6ms\n",
      "Speed: 1.2ms preprocess, 13.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 188/312 [00:07<00:05, 23.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 22.8ms\n",
      "Speed: 1.7ms preprocess, 22.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 191/312 [00:07<00:05, 22.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "Speed: 1.1ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.7ms\n",
      "Speed: 1.1ms preprocess, 11.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 194/312 [00:07<00:05, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 1.2ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 10.9ms\n",
      "Speed: 1.2ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bed, 1 cell phone, 11.5ms\n",
      "Speed: 1.4ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 197/312 [00:08<00:04, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 22.6ms\n",
      "Speed: 1.3ms preprocess, 22.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 16.6ms\n",
      "Speed: 1.3ms preprocess, 16.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.3ms\n",
      "Speed: 1.2ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 200/312 [00:08<00:04, 22.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.1ms\n",
      "Speed: 1.2ms preprocess, 11.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.2ms\n",
      "Speed: 1.2ms preprocess, 11.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 203/312 [00:08<00:04, 22.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 11.9ms\n",
      "Speed: 1.3ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 22.6ms\n",
      "Speed: 1.4ms preprocess, 22.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 206/312 [00:08<00:04, 22.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 21.9ms\n",
      "Speed: 1.3ms preprocess, 21.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 23.5ms\n",
      "Speed: 1.3ms preprocess, 23.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 209/312 [00:08<00:04, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 24.7ms\n",
      "Speed: 1.3ms preprocess, 24.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 20.2ms\n",
      "Speed: 1.3ms preprocess, 20.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 21.0ms\n",
      "Speed: 1.2ms preprocess, 21.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 212/312 [00:08<00:04, 20.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 21.8ms\n",
      "Speed: 1.2ms preprocess, 21.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 22.0ms\n",
      "Speed: 1.6ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 18.5ms\n",
      "Speed: 1.2ms preprocess, 18.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 215/312 [00:08<00:04, 20.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 18.9ms\n",
      "Speed: 1.3ms preprocess, 18.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 22.4ms\n",
      "Speed: 1.2ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 218/312 [00:09<00:04, 20.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 1.1ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "Speed: 1.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 18.2ms\n",
      "Speed: 1.9ms preprocess, 18.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 221/312 [00:09<00:04, 20.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.2ms\n",
      "Speed: 1.3ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 21.6ms\n",
      "Speed: 1.4ms preprocess, 21.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 13.5ms\n",
      "Speed: 1.6ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 224/312 [00:09<00:04, 20.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 13.7ms\n",
      "Speed: 1.2ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 227/312 [00:09<00:04, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 15.9ms\n",
      "Speed: 1.8ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 15.0ms\n",
      "Speed: 1.3ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 230/312 [00:09<00:03, 21.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 17.5ms\n",
      "Speed: 1.3ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.8ms\n",
      "Speed: 1.4ms preprocess, 13.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 1.8ms preprocess, 16.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 233/312 [00:09<00:03, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 2.1ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.7ms\n",
      "Speed: 1.8ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 236/312 [00:09<00:03, 22.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 239/312 [00:10<00:03, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 22.2ms\n",
      "Speed: 1.6ms preprocess, 22.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 242/312 [00:10<00:03, 22.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 cell phone, 14.9ms\n",
      "Speed: 2.1ms preprocess, 14.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 15.1ms\n",
      "Speed: 1.3ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 20.1ms\n",
      "Speed: 1.5ms preprocess, 20.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 245/312 [00:10<00:03, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 book, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 12.7ms\n",
      "Speed: 1.4ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 book, 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 248/312 [00:10<00:02, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 book, 17.3ms\n",
      "Speed: 1.7ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 laptop, 1 book, 14.7ms\n",
      "Speed: 1.6ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 book, 14.2ms\n",
      "Speed: 1.4ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 251/312 [00:10<00:02, 20.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 14.3ms\n",
      "Speed: 1.8ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.5ms\n",
      "Speed: 2.4ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 254/312 [00:10<00:02, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 257/312 [00:10<00:02, 21.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 14.7ms\n",
      "Speed: 2.3ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.0ms\n",
      "Speed: 1.3ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 260/312 [00:11<00:02, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 11.8ms\n",
      "Speed: 1.4ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.9ms\n",
      "Speed: 1.5ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 263/312 [00:11<00:02, 21.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 12.4ms\n",
      "Speed: 1.6ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.9ms\n",
      "Speed: 1.3ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 266/312 [00:11<00:02, 22.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 15.9ms\n",
      "Speed: 1.5ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 12.0ms\n",
      "Speed: 1.6ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 269/312 [00:11<00:02, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.6ms\n",
      "Speed: 1.4ms preprocess, 15.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 1.4ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 272/312 [00:11<00:01, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 16.2ms\n",
      "Speed: 1.9ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.1ms\n",
      "Speed: 2.1ms preprocess, 24.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 275/312 [00:11<00:01, 21.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.8ms\n",
      "Speed: 1.5ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.5ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 278/312 [00:11<00:01, 22.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.4ms\n",
      "Speed: 2.2ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.5ms\n",
      "Speed: 1.6ms preprocess, 20.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 281/312 [00:12<00:01, 21.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 2.1ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 1.7ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 284/312 [00:12<00:01, 22.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 13.4ms\n",
      "Speed: 2.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 1.4ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 287/312 [00:12<00:01, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 21.6ms\n",
      "Speed: 1.4ms preprocess, 21.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 suitcase, 11.6ms\n",
      "Speed: 1.6ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.8ms\n",
      "Speed: 1.8ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 290/312 [00:12<00:00, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 chair, 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 suitcase, 1 chair, 11.5ms\n",
      "Speed: 1.6ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 backpack, 1 chair, 12.2ms\n",
      "Speed: 1.8ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 293/312 [00:12<00:00, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 296/312 [00:12<00:00, 21.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 chair, 12.6ms\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.7ms preprocess, 11.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.4ms\n",
      "Speed: 1.4ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 299/312 [00:12<00:00, 22.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 19.9ms\n",
      "Speed: 1.6ms preprocess, 19.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.3ms\n",
      "Speed: 1.5ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 suitcase, 12.2ms\n",
      "Speed: 1.2ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 302/312 [00:12<00:00, 22.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 15.3ms\n",
      "Speed: 1.4ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 1.4ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 305/312 [00:13<00:00, 22.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.6ms\n",
      "Speed: 1.5ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.7ms\n",
      "Speed: 1.4ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 308/312 [00:13<00:00, 22.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.2ms\n",
      "Speed: 1.4ms preprocess, 12.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 19.4ms\n",
      "Speed: 2.2ms preprocess, 19.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 1.6ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 311/312 [00:13<00:00, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 312/312 [00:13<00:00, 23.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processed and saved as videos/veriff10_annotated.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process the video and create a new one with bounding boxes\n",
    "output_file = \"videos/veriff10_annotated.mp4\"\n",
    "processed_video = process_video_with_boxes(\"videos/veriff10.mp4\", output_file, model)\n",
    "\n",
    "print(f\"Video processed and saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38fcb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "video 1/1 (frame 1/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.1ms\n",
      "video 1/1 (frame 2/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.3ms\n",
      "video 1/1 (frame 3/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.8ms\n",
      "video 1/1 (frame 4/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.3ms\n",
      "video 1/1 (frame 5/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.7ms\n",
      "video 1/1 (frame 6/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 24.5ms\n",
      "video 1/1 (frame 7/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.4ms\n",
      "video 1/1 (frame 8/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.5ms\n",
      "video 1/1 (frame 9/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.7ms\n",
      "video 1/1 (frame 10/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.3ms\n",
      "video 1/1 (frame 11/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.3ms\n",
      "video 1/1 (frame 12/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.7ms\n",
      "video 1/1 (frame 13/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.4ms\n",
      "video 1/1 (frame 14/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.8ms\n",
      "video 1/1 (frame 15/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.2ms\n",
      "video 1/1 (frame 16/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.7ms\n",
      "video 1/1 (frame 17/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.7ms\n",
      "video 1/1 (frame 18/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.0ms\n",
      "video 1/1 (frame 19/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.3ms\n",
      "video 1/1 (frame 20/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.8ms\n",
      "video 1/1 (frame 21/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.9ms\n",
      "video 1/1 (frame 22/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.3ms\n",
      "video 1/1 (frame 23/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.1ms\n",
      "video 1/1 (frame 24/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.9ms\n",
      "video 1/1 (frame 25/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.5ms\n",
      "video 1/1 (frame 26/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.5ms\n",
      "video 1/1 (frame 27/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.7ms\n",
      "video 1/1 (frame 28/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 11.4ms\n",
      "video 1/1 (frame 29/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 15.8ms\n",
      "video 1/1 (frame 30/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.9ms\n",
      "video 1/1 (frame 31/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 13.1ms\n",
      "video 1/1 (frame 32/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 laptop, 1 cell phone, 14.2ms\n",
      "video 1/1 (frame 33/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 book, 23.5ms\n",
      "video 1/1 (frame 34/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 24.0ms\n",
      "video 1/1 (frame 35/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.4ms\n",
      "video 1/1 (frame 36/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.9ms\n",
      "video 1/1 (frame 37/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.9ms\n",
      "video 1/1 (frame 38/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.1ms\n",
      "video 1/1 (frame 39/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.1ms\n",
      "video 1/1 (frame 40/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.8ms\n",
      "video 1/1 (frame 41/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.3ms\n",
      "video 1/1 (frame 42/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.3ms\n",
      "video 1/1 (frame 43/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.2ms\n",
      "video 1/1 (frame 44/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.6ms\n",
      "video 1/1 (frame 45/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.7ms\n",
      "video 1/1 (frame 46/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.9ms\n",
      "video 1/1 (frame 47/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.5ms\n",
      "video 1/1 (frame 48/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.8ms\n",
      "video 1/1 (frame 49/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.2ms\n",
      "video 1/1 (frame 50/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 dog, 1 cell phone, 14.6ms\n",
      "video 1/1 (frame 51/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.1ms\n",
      "video 1/1 (frame 52/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.1ms\n",
      "video 1/1 (frame 53/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.1ms\n",
      "video 1/1 (frame 54/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.5ms\n",
      "video 1/1 (frame 55/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.8ms\n",
      "video 1/1 (frame 56/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.1ms\n",
      "video 1/1 (frame 57/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "video 1/1 (frame 58/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.8ms\n",
      "video 1/1 (frame 59/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.9ms\n",
      "video 1/1 (frame 60/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.8ms\n",
      "video 1/1 (frame 61/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.6ms\n",
      "video 1/1 (frame 62/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.0ms\n",
      "video 1/1 (frame 63/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 11.5ms\n",
      "video 1/1 (frame 64/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.3ms\n",
      "video 1/1 (frame 65/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.8ms\n",
      "video 1/1 (frame 66/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.0ms\n",
      "video 1/1 (frame 67/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 11.2ms\n",
      "video 1/1 (frame 68/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.5ms\n",
      "video 1/1 (frame 69/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.0ms\n",
      "video 1/1 (frame 70/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.7ms\n",
      "video 1/1 (frame 71/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.9ms\n",
      "video 1/1 (frame 72/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 22.5ms\n",
      "video 1/1 (frame 73/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.8ms\n",
      "video 1/1 (frame 74/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.5ms\n",
      "video 1/1 (frame 75/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.3ms\n",
      "video 1/1 (frame 76/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.9ms\n",
      "video 1/1 (frame 77/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.3ms\n",
      "video 1/1 (frame 78/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.7ms\n",
      "video 1/1 (frame 79/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.2ms\n",
      "video 1/1 (frame 80/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 17.3ms\n",
      "video 1/1 (frame 81/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 13.4ms\n",
      "video 1/1 (frame 82/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 16.8ms\n",
      "video 1/1 (frame 83/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 12.0ms\n",
      "video 1/1 (frame 84/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.0ms\n",
      "video 1/1 (frame 85/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.4ms\n",
      "video 1/1 (frame 86/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 26.2ms\n",
      "video 1/1 (frame 87/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.7ms\n",
      "video 1/1 (frame 88/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.7ms\n",
      "video 1/1 (frame 89/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.8ms\n",
      "video 1/1 (frame 90/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.8ms\n",
      "video 1/1 (frame 91/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 remote, 1 cell phone, 16.3ms\n",
      "video 1/1 (frame 92/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.8ms\n",
      "video 1/1 (frame 93/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 book, 17.1ms\n",
      "video 1/1 (frame 94/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 book, 26.2ms\n",
      "video 1/1 (frame 95/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 1 book, 30.0ms\n",
      "video 1/1 (frame 96/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cup, 15.4ms\n",
      "video 1/1 (frame 97/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cup, 16.1ms\n",
      "video 1/1 (frame 98/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cup, 20.2ms\n",
      "video 1/1 (frame 99/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.6ms\n",
      "video 1/1 (frame 100/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 19.4ms\n",
      "video 1/1 (frame 101/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 19.0ms\n",
      "video 1/1 (frame 102/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.6ms\n",
      "video 1/1 (frame 103/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.0ms\n",
      "video 1/1 (frame 104/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.9ms\n",
      "video 1/1 (frame 105/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.4ms\n",
      "video 1/1 (frame 106/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.0ms\n",
      "video 1/1 (frame 107/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.2ms\n",
      "video 1/1 (frame 108/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.0ms\n",
      "video 1/1 (frame 109/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.6ms\n",
      "video 1/1 (frame 110/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.7ms\n",
      "video 1/1 (frame 111/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.2ms\n",
      "video 1/1 (frame 112/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 23.6ms\n",
      "video 1/1 (frame 113/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.7ms\n",
      "video 1/1 (frame 114/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.6ms\n",
      "video 1/1 (frame 115/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.9ms\n",
      "video 1/1 (frame 116/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.3ms\n",
      "video 1/1 (frame 117/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 22.1ms\n",
      "video 1/1 (frame 118/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.8ms\n",
      "video 1/1 (frame 119/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.8ms\n",
      "video 1/1 (frame 120/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.6ms\n",
      "video 1/1 (frame 121/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 18.1ms\n",
      "video 1/1 (frame 122/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 25.7ms\n",
      "video 1/1 (frame 123/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.6ms\n",
      "video 1/1 (frame 124/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 23.3ms\n",
      "video 1/1 (frame 125/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.8ms\n",
      "video 1/1 (frame 126/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.6ms\n",
      "video 1/1 (frame 127/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 17.0ms\n",
      "video 1/1 (frame 128/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 17.4ms\n",
      "video 1/1 (frame 129/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.6ms\n",
      "video 1/1 (frame 130/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.2ms\n",
      "video 1/1 (frame 131/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.4ms\n",
      "video 1/1 (frame 132/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.9ms\n",
      "video 1/1 (frame 133/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.0ms\n",
      "video 1/1 (frame 134/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.8ms\n",
      "video 1/1 (frame 135/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.9ms\n",
      "video 1/1 (frame 136/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.7ms\n",
      "video 1/1 (frame 137/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.1ms\n",
      "video 1/1 (frame 138/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.6ms\n",
      "video 1/1 (frame 139/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.2ms\n",
      "video 1/1 (frame 140/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.9ms\n",
      "video 1/1 (frame 141/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.3ms\n",
      "video 1/1 (frame 142/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.1ms\n",
      "video 1/1 (frame 143/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.7ms\n",
      "video 1/1 (frame 144/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 19.3ms\n",
      "video 1/1 (frame 145/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.3ms\n",
      "video 1/1 (frame 146/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.1ms\n",
      "video 1/1 (frame 147/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.7ms\n",
      "video 1/1 (frame 148/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.8ms\n",
      "video 1/1 (frame 149/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.4ms\n",
      "video 1/1 (frame 150/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.3ms\n",
      "video 1/1 (frame 151/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 17.1ms\n",
      "video 1/1 (frame 152/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.0ms\n",
      "video 1/1 (frame 153/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.9ms\n",
      "video 1/1 (frame 154/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 19.8ms\n",
      "video 1/1 (frame 155/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 13.5ms\n",
      "video 1/1 (frame 156/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 12.9ms\n",
      "video 1/1 (frame 157/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 15.3ms\n",
      "video 1/1 (frame 158/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.2ms\n",
      "video 1/1 (frame 159/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 17.7ms\n",
      "video 1/1 (frame 160/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 16.1ms\n",
      "video 1/1 (frame 161/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 14.1ms\n",
      "video 1/1 (frame 162/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 26.9ms\n",
      "video 1/1 (frame 163/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "video 1/1 (frame 164/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.3ms\n",
      "video 1/1 (frame 165/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 13.5ms\n",
      "video 1/1 (frame 166/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 18.0ms\n",
      "video 1/1 (frame 167/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.4ms\n",
      "video 1/1 (frame 168/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 13.2ms\n",
      "video 1/1 (frame 169/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.9ms\n",
      "video 1/1 (frame 170/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.5ms\n",
      "video 1/1 (frame 171/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.3ms\n",
      "video 1/1 (frame 172/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.9ms\n",
      "video 1/1 (frame 173/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.4ms\n",
      "video 1/1 (frame 174/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.2ms\n",
      "video 1/1 (frame 175/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.5ms\n",
      "video 1/1 (frame 176/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.2ms\n",
      "video 1/1 (frame 177/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.1ms\n",
      "video 1/1 (frame 178/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 20.7ms\n",
      "video 1/1 (frame 179/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 25.5ms\n",
      "video 1/1 (frame 180/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 18.2ms\n",
      "video 1/1 (frame 181/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 pizza, 1 cell phone, 16.1ms\n",
      "video 1/1 (frame 182/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.2ms\n",
      "video 1/1 (frame 183/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.1ms\n",
      "video 1/1 (frame 184/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 24.0ms\n",
      "video 1/1 (frame 185/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.4ms\n",
      "video 1/1 (frame 186/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.0ms\n",
      "video 1/1 (frame 187/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 18.0ms\n",
      "video 1/1 (frame 188/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.8ms\n",
      "video 1/1 (frame 189/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.3ms\n",
      "video 1/1 (frame 190/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.5ms\n",
      "video 1/1 (frame 191/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.4ms\n",
      "video 1/1 (frame 192/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 13.1ms\n",
      "video 1/1 (frame 193/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 16.7ms\n",
      "video 1/1 (frame 194/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.6ms\n",
      "video 1/1 (frame 195/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.2ms\n",
      "video 1/1 (frame 196/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 21.2ms\n",
      "video 1/1 (frame 197/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 bed, 1 cell phone, 13.2ms\n",
      "video 1/1 (frame 198/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 14.6ms\n",
      "video 1/1 (frame 199/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 15.3ms\n",
      "video 1/1 (frame 200/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 24.4ms\n",
      "video 1/1 (frame 201/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 13.9ms\n",
      "video 1/1 (frame 202/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 15.3ms\n",
      "video 1/1 (frame 203/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 16.0ms\n",
      "video 1/1 (frame 204/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 13.6ms\n",
      "video 1/1 (frame 205/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 15.5ms\n",
      "video 1/1 (frame 206/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 12.1ms\n",
      "video 1/1 (frame 207/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.3ms\n",
      "video 1/1 (frame 208/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 20.8ms\n",
      "video 1/1 (frame 209/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 13.0ms\n",
      "video 1/1 (frame 210/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.8ms\n",
      "video 1/1 (frame 211/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 13.5ms\n",
      "video 1/1 (frame 212/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.3ms\n",
      "video 1/1 (frame 213/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 21.6ms\n",
      "video 1/1 (frame 214/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 20.2ms\n",
      "video 1/1 (frame 215/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.1ms\n",
      "video 1/1 (frame 216/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.1ms\n",
      "video 1/1 (frame 217/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.2ms\n",
      "video 1/1 (frame 218/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 11.6ms\n",
      "video 1/1 (frame 219/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.8ms\n",
      "video 1/1 (frame 220/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 13.8ms\n",
      "video 1/1 (frame 221/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.0ms\n",
      "video 1/1 (frame 222/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.5ms\n",
      "video 1/1 (frame 223/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 15.3ms\n",
      "video 1/1 (frame 224/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.1ms\n",
      "video 1/1 (frame 225/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 19.0ms\n",
      "video 1/1 (frame 226/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 13.1ms\n",
      "video 1/1 (frame 227/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.2ms\n",
      "video 1/1 (frame 228/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 cell phone, 18.2ms\n",
      "video 1/1 (frame 229/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.7ms\n",
      "video 1/1 (frame 230/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 18.7ms\n",
      "video 1/1 (frame 231/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 18.2ms\n",
      "video 1/1 (frame 232/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 27.6ms\n",
      "video 1/1 (frame 233/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.8ms\n",
      "video 1/1 (frame 234/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 16.1ms\n",
      "video 1/1 (frame 235/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 18.6ms\n",
      "video 1/1 (frame 236/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 19.2ms\n",
      "video 1/1 (frame 237/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.1ms\n",
      "video 1/1 (frame 238/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.0ms\n",
      "video 1/1 (frame 239/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 14.6ms\n",
      "video 1/1 (frame 240/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 17.0ms\n",
      "video 1/1 (frame 241/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 13.2ms\n",
      "video 1/1 (frame 242/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 26.8ms\n",
      "video 1/1 (frame 243/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "video 1/1 (frame 244/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 14.0ms\n",
      "video 1/1 (frame 245/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 cell phone, 12.4ms\n",
      "video 1/1 (frame 246/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 1 book, 11.9ms\n",
      "video 1/1 (frame 247/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 book, 13.9ms\n",
      "video 1/1 (frame 248/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 1 book, 17.1ms\n",
      "video 1/1 (frame 249/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 1 book, 11.6ms\n",
      "video 1/1 (frame 250/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 laptop, 1 book, 16.8ms\n",
      "video 1/1 (frame 251/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 book, 11.6ms\n",
      "video 1/1 (frame 252/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 24.6ms\n",
      "video 1/1 (frame 253/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 23.4ms\n",
      "video 1/1 (frame 254/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.4ms\n",
      "video 1/1 (frame 255/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.5ms\n",
      "video 1/1 (frame 256/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.7ms\n",
      "video 1/1 (frame 257/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.9ms\n",
      "video 1/1 (frame 258/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 12.1ms\n",
      "video 1/1 (frame 259/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 21.9ms\n",
      "video 1/1 (frame 260/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 15.1ms\n",
      "video 1/1 (frame 261/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 15.8ms\n",
      "video 1/1 (frame 262/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 14.2ms\n",
      "video 1/1 (frame 263/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 11.8ms\n",
      "video 1/1 (frame 264/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 12.5ms\n",
      "video 1/1 (frame 265/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 13.5ms\n",
      "video 1/1 (frame 266/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 14.6ms\n",
      "video 1/1 (frame 267/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 17.8ms\n",
      "video 1/1 (frame 268/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 15.4ms\n",
      "video 1/1 (frame 269/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 3 persons, 12.3ms\n",
      "video 1/1 (frame 270/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.9ms\n",
      "video 1/1 (frame 271/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.7ms\n",
      "video 1/1 (frame 272/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.7ms\n",
      "video 1/1 (frame 273/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.2ms\n",
      "video 1/1 (frame 274/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.3ms\n",
      "video 1/1 (frame 275/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.2ms\n",
      "video 1/1 (frame 276/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.9ms\n",
      "video 1/1 (frame 277/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.3ms\n",
      "video 1/1 (frame 278/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 22.9ms\n",
      "video 1/1 (frame 279/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.3ms\n",
      "video 1/1 (frame 280/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.6ms\n",
      "video 1/1 (frame 281/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.4ms\n",
      "video 1/1 (frame 282/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.3ms\n",
      "video 1/1 (frame 283/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 22.0ms\n",
      "video 1/1 (frame 284/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 20.8ms\n",
      "video 1/1 (frame 285/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.9ms\n",
      "video 1/1 (frame 286/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.5ms\n",
      "video 1/1 (frame 287/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 22.6ms\n",
      "video 1/1 (frame 288/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 32.2ms\n",
      "video 1/1 (frame 289/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 suitcase, 17.2ms\n",
      "video 1/1 (frame 290/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 18.3ms\n",
      "video 1/1 (frame 291/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 chair, 16.0ms\n",
      "video 1/1 (frame 292/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 suitcase, 1 chair, 15.0ms\n",
      "video 1/1 (frame 293/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 backpack, 1 chair, 15.6ms\n",
      "video 1/1 (frame 294/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.1ms\n",
      "video 1/1 (frame 295/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 chair, 14.2ms\n",
      "video 1/1 (frame 296/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.5ms\n",
      "video 1/1 (frame 297/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 1 chair, 14.3ms\n",
      "video 1/1 (frame 298/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 17.0ms\n",
      "video 1/1 (frame 299/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 17.2ms\n",
      "video 1/1 (frame 300/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 15.1ms\n",
      "video 1/1 (frame 301/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 18.5ms\n",
      "video 1/1 (frame 302/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 1 suitcase, 13.7ms\n",
      "video 1/1 (frame 303/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 16.4ms\n",
      "video 1/1 (frame 304/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.7ms\n",
      "video 1/1 (frame 305/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.2ms\n",
      "video 1/1 (frame 306/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 2 persons, 14.9ms\n",
      "video 1/1 (frame 307/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 17.2ms\n",
      "video 1/1 (frame 308/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.7ms\n",
      "video 1/1 (frame 309/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 14.4ms\n",
      "video 1/1 (frame 310/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 11.8ms\n",
      "video 1/1 (frame 311/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 12.1ms\n",
      "video 1/1 (frame 312/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.4ms\n",
      "Speed: 1.5ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Processed 312 frames\n",
      "Frames with multiple people: 36 (11.5%)\n",
      "Max people in a frame: 3\n",
      "Average people per frame: 1.12\n"
     ]
    }
   ],
   "source": [
    "# Instead of printing class IDs for every frame, let's collect statistics\n",
    "results = model(\"videos/veriff10.mp4\", stream=True)\n",
    "\n",
    "# Initialize counters\n",
    "person_count_per_frame = []\n",
    "frames_with_multiple_people = 0\n",
    "total_frames = 0\n",
    "\n",
    "# Process each frame silently\n",
    "for result in results:\n",
    "    total_frames += 1\n",
    "    # Count persons in this frame\n",
    "    person_count = sum(1 for cls in result.boxes.cls if int(cls) == 0)\n",
    "    person_count_per_frame.append(person_count)\n",
    "    if person_count > 1:\n",
    "        frames_with_multiple_people += 1\n",
    "\n",
    "# Print just a summary\n",
    "print(f\"Processed {total_frames} frames\")\n",
    "print(f\"Frames with multiple people: {frames_with_multiple_people} ({frames_with_multiple_people/total_frames*100:.1f}%)\")\n",
    "print(f\"Max people in a frame: {max(person_count_per_frame)}\")\n",
    "print(f\"Average people per frame: {sum(person_count_per_frame)/total_frames:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f58b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "video 1/1 (frame 1/312) c:\\Users\\Ilmar\\hobby_projects\\coercion-check\\src\\videos\\veriff10.mp4: 384x640 1 person, 13.4ms\n",
      "Starting\n",
      "Result: ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[180, 189, 193],\n",
      "        [180, 189, 193],\n",
      "        [180, 189, 193],\n",
      "        ...,\n",
      "        [ 92,  72,  74],\n",
      "        [ 98,  78,  80],\n",
      "        [ 97,  77,  79]],\n",
      "\n",
      "       [[179, 188, 192],\n",
      "        [179, 188, 192],\n",
      "        [179, 188, 192],\n",
      "        ...,\n",
      "        [ 99,  79,  81],\n",
      "        [100,  80,  82],\n",
      "        [ 96,  76,  78]],\n",
      "\n",
      "       [[179, 188, 192],\n",
      "        [179, 188, 192],\n",
      "        [179, 188, 192],\n",
      "        ...,\n",
      "        [112,  92,  94],\n",
      "        [108,  88,  90],\n",
      "        [100,  80,  82]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]]], dtype=uint8)\n",
      "orig_shape: (1080, 1920)\n",
      "path: 'c:\\\\Users\\\\Ilmar\\\\hobby_projects\\\\coercion-check\\\\src\\\\videos\\\\veriff10.mp4'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 2.5215000000002874, 'inference': 13.356800000011049, 'postprocess': 2.004299999995851}\n",
      "Boxes: ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.], device='cuda:0')\n",
      "conf: tensor([0.9599], device='cuda:0')\n",
      "data: tensor([[6.1444e+02, 4.5772e+00, 1.9148e+03, 1.0604e+03, 9.5991e-01, 0.0000e+00]], device='cuda:0')\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (1080, 1920)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[1264.6245,  532.4830, 1300.3674, 1055.8116]], device='cuda:0')\n",
      "xywhn: tensor([[0.6587, 0.4930, 0.6773, 0.9776]], device='cuda:0')\n",
      "xyxy: tensor([[ 614.4408,    4.5772, 1914.8082, 1060.3888]], device='cuda:0')\n",
      "xyxyn: tensor([[0.3200, 0.0042, 0.9973, 0.9818]], device='cuda:0')\n",
      "Classes: tensor([0.], device='cuda:0')\n",
      "Confidences: tensor([0.9599], device='cuda:0')\n",
      "Keypoints: None\n",
      "Masks: None\n",
      "Speed: {'preprocess': 2.5215000000002874, 'inference': 13.356800000011049, 'postprocess': 2.004299999995851}\n",
      "Names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "# Instead of printing class IDs for every frame, let's collect statistics\n",
    "results = model(\"videos/veriff10.mp4\", stream=True)\n",
    "\n",
    "for result in results:\n",
    "    print(\"Starting\")\n",
    "    print(f\"Result: {result}\")\n",
    "    print(f\"Boxes: {result.boxes}\")\n",
    "    print(f\"Classes: {result.boxes.cls}\")\n",
    "    print(f\"Confidences: {result.boxes.conf}\")\n",
    "    print(f\"Keypoints: {result.keypoints}\")\n",
    "    print(f\"Masks: {result.masks}\")\n",
    "    print(f\"Speed: {result.speed}\")\n",
    "    print(f\"Names: {model.names}\")  # Class names\n",
    "    break  # Just inspect the first result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f526cb93",
   "metadata": {},
   "source": [
    "Person is class 0. With each frame and class info, there's also a confidence between 0 to 1. It sometimes happens the the YOLO object detection model 'detects' people, but it's actually a false positive. To combat this issue, we can add a threshold for confidence and classify frames under that threshold to not contain people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f1dd8",
   "metadata": {},
   "source": [
    "## Adding object tracking (Deep SORT)\n",
    "\n",
    "We want to track and label different people across frames (e.g. Person 1, Person 2 etc), so we need to combine our object detection model (YOLO) with multi-object tracking. Deep SORT does this by using a Kalman filter for motion prediction and ReID embeddings for appearance similarity, resulting in each person getting a persistent ID like Person 3, Person 7 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60cd954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Person Appearance Log:\n",
      "Person 1: seen in 310 frames, avg confidence: 0.64\n",
      "    First appearance: frame 2, confidence: 0.95\n",
      "    Last appearance: frame 311, confidence: 0.92\n",
      "Person 2: seen in 32 frames, avg confidence: 0.00\n",
      "    First appearance: frame 203, confidence: 0.00\n",
      "    Last appearance: frame 234, confidence: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Initialize Deep SORT tracker\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "# Load video\n",
    "video_path = \"videos/veriff10.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Output video\n",
    "output = cv2.VideoWriter(\"videos/veriff10_tracked.mp4\", cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                         cap.get(cv2.CAP_PROP_FPS),\n",
    "                         (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Tracking dictionary with nested structure for frames and confidences\n",
    "person_items = defaultdict(lambda: {\"frames\": [], \"confidences\": []})\n",
    "\n",
    "frame_idx = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame, verbose=False, conf = 0.6)[0]\n",
    "\n",
    "    detections = []\n",
    "    for box in results.boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if cls == 0:  # person class only\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            detections.append([[x1, y1, x2 - x1, y2 - y1], conf, 'person'])\n",
    "\n",
    "    # Update Deep SORT\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        l, t, r, b = map(int, track.to_ltrb())\n",
    "\n",
    "        # Find the corresponding detection and its confidence\n",
    "        detection_conf = 0\n",
    "        for det, conf, _ in detections:\n",
    "            det_x1, det_y1, det_w, det_h = det\n",
    "            det_x2, det_y2 = det_x1 + det_w, det_y1 + det_h\n",
    "            # Check if this detection box matches the track box\n",
    "            if abs(l - det_x1) < 20 and abs(t - det_y1) < 20 and abs(r - det_x2) < 20 and abs(b - det_y2) < 20:\n",
    "                detection_conf = conf\n",
    "                break\n",
    "\n",
    "        # Log the current frame and confidence for this person\n",
    "        person_items[track_id][\"frames\"].append(frame_idx)\n",
    "        person_items[track_id][\"confidences\"].append(detection_conf)\n",
    "\n",
    "        # Draw box and label with confidence\n",
    "        cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)\n",
    "        label = f\"Person {track_id} ({detection_conf:.2f})\"\n",
    "        cv2.putText(frame, label, (l, t - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    output.write(frame)\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    frame_idx += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Output the log with confidence information\n",
    "print(\"\\n Person Appearance Log:\")\n",
    "for pid, data in person_items.items():\n",
    "    frames = data[\"frames\"]\n",
    "    confidences = data[\"confidences\"]\n",
    "    avg_conf = sum(confidences) / len(confidences) if confidences else 0\n",
    "    print(f\"Person {pid}: seen in {len(frames)} frames, avg confidence: {avg_conf:.2f}\")\n",
    "    print(f\"    First appearance: frame {frames[0]}, confidence: {confidences[0]:.2f}\")\n",
    "    print(f\"    Last appearance: frame {frames[-1]}, confidence: {confidences[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9b170",
   "metadata": {},
   "source": [
    "### Defining function for whole ETL and predict pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2a03f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coercion_check(video_paths, model, conf_threshold=0.5):\n",
    "    coercion_results = []\n",
    "    tracker = DeepSort(max_age=30)\n",
    "    \n",
    "    for video_path in video_paths:\n",
    "        print(f\"Processing {video_path}...\")\n",
    "        results = person_detection_and_tracking(video_path, model, tracker, conf_threshold)\n",
    "        \n",
    "        print(f\"Found {len(results)} unique persons in {video_path}\\n\")\n",
    "        coercion_detected = int(len(results) > 1)   \n",
    "        for person_id, data in results.items():\n",
    "            frames = data[\"frames\"]\n",
    "            confidences = data[\"confidences\"]\n",
    "            avg_conf = sum(confidences) / len(confidences) if confidences else 0\n",
    "            \n",
    "            coercion_results.append({\n",
    "                \"video_path\": video_path,\n",
    "                \"video\": video_path.split(\"\\\\\")[-1][:-4],\n",
    "                \"person_id\": person_id,\n",
    "                \"num_frames\": len(frames),\n",
    "                \"avg_confidence\": avg_conf,\n",
    "                \"confidence_threshold\": conf_threshold,\n",
    "                \"first_frame\": frames[0],\n",
    "                \"last_frame\": frames[-1],\n",
    "                \"coercion_detected\": coercion_detected\n",
    "            })\n",
    "\n",
    "    coercion_results_df = pd.DataFrame(coercion_results)\n",
    "    print(f\"Processed {coercion_results_df.video.nunique()} unique videos with coercion detection results.\")\n",
    "    return coercion_results_df\n",
    "\n",
    "def person_detection_and_tracking(video_path, model, tracker, conf_threshold=0.5):\n",
    "    # Initialize Deep SORT tracker\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Tracking dictionary with nested structure for frames and confidences\n",
    "    person_items = defaultdict(lambda: {\"frames\": [], \"confidences\": []})\n",
    "\n",
    "    frame_idx = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = model(frame, verbose=False, conf = conf_threshold)[0]\n",
    "\n",
    "        detections = []\n",
    "        for box in results.boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            if cls == 0:  # person class only\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                detections.append([[x1, y1, x2 - x1, y2 - y1], conf, 'person'])\n",
    "\n",
    "        # Update Deep SORT\n",
    "        tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed():\n",
    "                continue\n",
    "            track_id = track.track_id\n",
    "            l, t, r, b = map(int, track.to_ltrb())\n",
    "\n",
    "            # Find the corresponding detection and its confidence\n",
    "            detection_conf = 0\n",
    "            for det, conf, _ in detections:\n",
    "                det_x1, det_y1, det_w, det_h = det\n",
    "                det_x2, det_y2 = det_x1 + det_w, det_y1 + det_h\n",
    "                # Check if this detection box matches the track box\n",
    "                if abs(l - det_x1) < 20 and abs(t - det_y1) < 20 and abs(r - det_x2) < 20 and abs(b - det_y2) < 20:\n",
    "                    detection_conf = conf\n",
    "                    break\n",
    "\n",
    "            # Log the current frame and confidence for this person\n",
    "            person_items[track_id][\"frames\"].append(frame_idx)\n",
    "            person_items[track_id][\"confidences\"].append(detection_conf)\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return person_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f816fd",
   "metadata": {},
   "source": [
    "## Fine-tuning model\n",
    "\n",
    "### Loading labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389fcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90133915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>veriff1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>veriff2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veriff3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>veriff4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>veriff5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     video  label\n",
       "0  veriff1      0\n",
       "1  veriff2      1\n",
       "2  veriff3      0\n",
       "3  veriff4      1\n",
       "4  veriff5      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"videos/labels.txt\", sep = \"\\t\")\n",
    "print(\"labels.info()\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "055de684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17 entries, 0 to 16\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   video   17 non-null     object\n",
      " 1   label   17 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 400.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c3768",
   "metadata": {},
   "source": [
    "### Functions for prediction and comparing results/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fd661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing videos\\veriff2.mp4...\n",
      "Found 1 unique persons in videos\\veriff2.mp4\n",
      "\n",
      "Processed 1 unique videos with coercion detection results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_path</th>\n",
       "      <th>video</th>\n",
       "      <th>person_id</th>\n",
       "      <th>num_frames</th>\n",
       "      <th>avg_confidence</th>\n",
       "      <th>confidence_threshold</th>\n",
       "      <th>first_frame</th>\n",
       "      <th>last_frame</th>\n",
       "      <th>coercion_detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>videos\\veriff2.mp4</td>\n",
       "      <td>veriff2</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>0.834001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           video_path    video person_id  num_frames  avg_confidence  \\\n",
       "0  videos\\veriff2.mp4  veriff2         1         207        0.834001   \n",
       "\n",
       "   confidence_threshold  first_frame  last_frame  coercion_detected  \n",
       "0                   0.4            0           0                  0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(\"models/yolov8m.pt\")  # yolov8n.pt, yolov8s.pt or yolov8m.pt for better accuracy\n",
    "\n",
    "video_paths = glob.glob(\"videos/veriff*.mp4\")\n",
    "\n",
    "coercion_results = make_coercion_check(video_paths, model, conf_threshold=0.4)\n",
    "coercion_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "254d2f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coercion detection accuracy: 70.59%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       video  coercion_detected  label  match\n",
       " 0    veriff1                  0      0   True\n",
       " 1    veriff2                  1      1   True\n",
       " 2    veriff3                  0      0   True\n",
       " 3    veriff4                  1      1   True\n",
       " 4    veriff5                  1      0  False\n",
       " 5    veriff6                  0      0   True\n",
       " 6    veriff7                  0      0   True\n",
       " 7    veriff8                  0      0   True\n",
       " 8    veriff9                  0      1  False\n",
       " 9   veriff10                  1      1   True\n",
       " 10  veriff11                  0      0   True\n",
       " 11  veriff12                  1      1   True\n",
       " 12  veriff14                  0      0   True\n",
       " 13  veriff16                  1      1   True\n",
       " 14  veriff17                  1      0  False\n",
       " 15  veriff18                  1      0  False\n",
       " 16  veriff19                  0      1  False,\n",
       " np.float64(70.58823529411765))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def coercion_check_results(coercion_results, labels):\n",
    "    final_results = pd.DataFrame(coercion_results.groupby(\"video\")['coercion_detected'].mean())\n",
    "    final_results = final_results.reset_index()\n",
    "    final_results.columns = ['video', 'coercion_detected']\n",
    "    final_results['coercion_detected'] = final_results['coercion_detected'].astype(int)\n",
    "    final_results = final_results.merge(labels, on='video', how='right')\n",
    "    final_results['match'] = final_results['coercion_detected'] == final_results['label']\n",
    "    accuracy = final_results['match'].mean() * 100\n",
    "    print(f\"Coercion detection accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return final_results, accuracy\n",
    "\n",
    "coercion_check_results(coercion_results, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a2c2f",
   "metadata": {},
   "source": [
    "### Testing different detection confidence thresholds\n",
    "\n",
    "I need to check how different detection confidence thresholds affect prediction results and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1dce72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_confidence_thresholds(video_paths, model, thresholds):\n",
    "    results_dict = {}\n",
    "    for threshold in thresholds:\n",
    "        print(f\"Testing with confidence threshold: {threshold}\")\n",
    "        coercion_df = make_coercion_check(video_paths, model, conf_threshold=threshold)\n",
    "        coercion_results, accuracy = coercion_check_results(coercion_df, labels)\n",
    "        coercion_df['confidence_threshold'] = threshold\n",
    "        results_dict[threshold] = (coercion_results, accuracy)\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4da30eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with confidence threshold: 0.3\n",
      "Processing videos\\veriff1.mp4...\n",
      "Found 2 unique persons in videos\\veriff1.mp4\n",
      "\n",
      "Processing videos\\veriff10.mp4...\n",
      "Found 3 unique persons in videos\\veriff10.mp4\n",
      "\n",
      "Processing videos\\veriff11.mp4...\n",
      "Found 3 unique persons in videos\\veriff11.mp4\n",
      "\n",
      "Processing videos\\veriff12.mp4...\n",
      "Found 12 unique persons in videos\\veriff12.mp4\n",
      "\n",
      "Processing videos\\veriff14.mp4...\n",
      "Found 5 unique persons in videos\\veriff14.mp4\n",
      "\n",
      "Processing videos\\veriff16.mp4...\n",
      "Found 9 unique persons in videos\\veriff16.mp4\n",
      "\n",
      "Processing videos\\veriff17.mp4...\n",
      "Found 15 unique persons in videos\\veriff17.mp4\n",
      "\n",
      "Processing videos\\veriff18.mp4...\n",
      "Found 14 unique persons in videos\\veriff18.mp4\n",
      "\n",
      "Processing videos\\veriff19.mp4...\n",
      "Found 2 unique persons in videos\\veriff19.mp4\n",
      "\n",
      "Processing videos\\veriff2.mp4...\n",
      "Found 1 unique persons in videos\\veriff2.mp4\n",
      "\n",
      "Processing videos\\veriff3.mp4...\n",
      "Found 1 unique persons in videos\\veriff3.mp4\n",
      "\n",
      "Processing videos\\veriff4.mp4...\n",
      "Found 160 unique persons in videos\\veriff4.mp4\n",
      "\n",
      "Processing videos\\veriff5.mp4...\n",
      "Found 18 unique persons in videos\\veriff5.mp4\n",
      "\n",
      "Processing videos\\veriff6.mp4...\n",
      "Found 1 unique persons in videos\\veriff6.mp4\n",
      "\n",
      "Processing videos\\veriff7.mp4...\n",
      "Found 1 unique persons in videos\\veriff7.mp4\n",
      "\n",
      "Processing videos\\veriff8.mp4...\n",
      "Found 3 unique persons in videos\\veriff8.mp4\n",
      "\n",
      "Processing videos\\veriff9.mp4...\n",
      "Found 6 unique persons in videos\\veriff9.mp4\n",
      "\n",
      "Processed 17 unique videos with coercion detection results.\n",
      "Coercion detection accuracy: 52.94%\n",
      "Testing with confidence threshold: 0.45\n",
      "Processing videos\\veriff1.mp4...\n",
      "Found 2 unique persons in videos\\veriff1.mp4\n",
      "\n",
      "Processing videos\\veriff10.mp4...\n",
      "Found 3 unique persons in videos\\veriff10.mp4\n",
      "\n",
      "Processing videos\\veriff11.mp4...\n",
      "Found 1 unique persons in videos\\veriff11.mp4\n",
      "\n",
      "Processing videos\\veriff12.mp4...\n",
      "Found 7 unique persons in videos\\veriff12.mp4\n",
      "\n",
      "Processing videos\\veriff14.mp4...\n",
      "Found 2 unique persons in videos\\veriff14.mp4\n",
      "\n",
      "Processing videos\\veriff16.mp4...\n",
      "Found 6 unique persons in videos\\veriff16.mp4\n",
      "\n",
      "Processing videos\\veriff17.mp4...\n",
      "Found 13 unique persons in videos\\veriff17.mp4\n",
      "\n",
      "Processing videos\\veriff18.mp4...\n",
      "Found 13 unique persons in videos\\veriff18.mp4\n",
      "\n",
      "Processing videos\\veriff19.mp4...\n",
      "Found 1 unique persons in videos\\veriff19.mp4\n",
      "\n",
      "Processing videos\\veriff2.mp4...\n",
      "Found 1 unique persons in videos\\veriff2.mp4\n",
      "\n",
      "Processing videos\\veriff3.mp4...\n",
      "Found 1 unique persons in videos\\veriff3.mp4\n",
      "\n",
      "Processing videos\\veriff4.mp4...\n",
      "Found 118 unique persons in videos\\veriff4.mp4\n",
      "\n",
      "Processing videos\\veriff5.mp4...\n",
      "Found 14 unique persons in videos\\veriff5.mp4\n",
      "\n",
      "Processing videos\\veriff6.mp4...\n",
      "Found 1 unique persons in videos\\veriff6.mp4\n",
      "\n",
      "Processing videos\\veriff7.mp4...\n",
      "Found 1 unique persons in videos\\veriff7.mp4\n",
      "\n",
      "Processing videos\\veriff8.mp4...\n",
      "Found 1 unique persons in videos\\veriff8.mp4\n",
      "\n",
      "Processing videos\\veriff9.mp4...\n",
      "Found 4 unique persons in videos\\veriff9.mp4\n",
      "\n",
      "Processed 17 unique videos with coercion detection results.\n",
      "Coercion detection accuracy: 58.82%\n",
      "Testing with confidence threshold: 0.5\n",
      "Processing videos\\veriff1.mp4...\n",
      "Found 2 unique persons in videos\\veriff1.mp4\n",
      "\n",
      "Processing videos\\veriff10.mp4...\n",
      "Found 3 unique persons in videos\\veriff10.mp4\n",
      "\n",
      "Processing videos\\veriff11.mp4...\n",
      "Found 1 unique persons in videos\\veriff11.mp4\n",
      "\n",
      "Processing videos\\veriff12.mp4...\n",
      "Found 7 unique persons in videos\\veriff12.mp4\n",
      "\n",
      "Processing videos\\veriff14.mp4...\n",
      "Found 3 unique persons in videos\\veriff14.mp4\n",
      "\n",
      "Processing videos\\veriff16.mp4...\n",
      "Found 4 unique persons in videos\\veriff16.mp4\n",
      "\n",
      "Processing videos\\veriff17.mp4...\n",
      "Found 13 unique persons in videos\\veriff17.mp4\n",
      "\n",
      "Processing videos\\veriff18.mp4...\n",
      "Found 9 unique persons in videos\\veriff18.mp4\n",
      "\n",
      "Processing videos\\veriff19.mp4...\n",
      "Found 1 unique persons in videos\\veriff19.mp4\n",
      "\n",
      "Processing videos\\veriff2.mp4...\n",
      "Found 1 unique persons in videos\\veriff2.mp4\n",
      "\n",
      "Processing videos\\veriff3.mp4...\n",
      "Found 1 unique persons in videos\\veriff3.mp4\n",
      "\n",
      "Processing videos\\veriff4.mp4...\n",
      "Found 116 unique persons in videos\\veriff4.mp4\n",
      "\n",
      "Processing videos\\veriff5.mp4...\n",
      "Found 14 unique persons in videos\\veriff5.mp4\n",
      "\n",
      "Processing videos\\veriff6.mp4...\n",
      "Found 1 unique persons in videos\\veriff6.mp4\n",
      "\n",
      "Processing videos\\veriff7.mp4...\n",
      "Found 1 unique persons in videos\\veriff7.mp4\n",
      "\n",
      "Processing videos\\veriff8.mp4...\n",
      "Found 1 unique persons in videos\\veriff8.mp4\n",
      "\n",
      "Processing videos\\veriff9.mp4...\n",
      "Found 2 unique persons in videos\\veriff9.mp4\n",
      "\n",
      "Processed 17 unique videos with coercion detection results.\n",
      "Coercion detection accuracy: 58.82%\n",
      "Testing with confidence threshold: 0.55\n",
      "Processing videos\\veriff1.mp4...\n",
      "Found 2 unique persons in videos\\veriff1.mp4\n",
      "\n",
      "Processing videos\\veriff10.mp4...\n",
      "Found 3 unique persons in videos\\veriff10.mp4\n",
      "\n",
      "Processing videos\\veriff11.mp4...\n",
      "Found 1 unique persons in videos\\veriff11.mp4\n",
      "\n",
      "Processing videos\\veriff12.mp4...\n",
      "Found 8 unique persons in videos\\veriff12.mp4\n",
      "\n",
      "Processing videos\\veriff14.mp4...\n",
      "Found 2 unique persons in videos\\veriff14.mp4\n",
      "\n",
      "Processing videos\\veriff16.mp4...\n",
      "Found 4 unique persons in videos\\veriff16.mp4\n",
      "\n",
      "Processing videos\\veriff17.mp4...\n",
      "Found 11 unique persons in videos\\veriff17.mp4\n",
      "\n",
      "Processing videos\\veriff18.mp4...\n",
      "Found 10 unique persons in videos\\veriff18.mp4\n",
      "\n",
      "Processing videos\\veriff19.mp4...\n",
      "Found 1 unique persons in videos\\veriff19.mp4\n",
      "\n",
      "Processing videos\\veriff2.mp4...\n",
      "Found 1 unique persons in videos\\veriff2.mp4\n",
      "\n",
      "Processing videos\\veriff3.mp4...\n",
      "Found 1 unique persons in videos\\veriff3.mp4\n",
      "\n",
      "Processing videos\\veriff4.mp4...\n",
      "Found 104 unique persons in videos\\veriff4.mp4\n",
      "\n",
      "Processing videos\\veriff5.mp4...\n",
      "Found 13 unique persons in videos\\veriff5.mp4\n",
      "\n",
      "Processing videos\\veriff6.mp4...\n",
      "Found 1 unique persons in videos\\veriff6.mp4\n",
      "\n",
      "Processing videos\\veriff7.mp4...\n",
      "Found 1 unique persons in videos\\veriff7.mp4\n",
      "\n",
      "Processing videos\\veriff8.mp4...\n",
      "Found 1 unique persons in videos\\veriff8.mp4\n",
      "\n",
      "Processing videos\\veriff9.mp4...\n",
      "Found 2 unique persons in videos\\veriff9.mp4\n",
      "\n",
      "Processed 17 unique videos with coercion detection results.\n",
      "Coercion detection accuracy: 58.82%\n",
      "Testing with confidence threshold: 0.6\n",
      "Processing videos\\veriff1.mp4...\n",
      "Found 1 unique persons in videos\\veriff1.mp4\n",
      "\n",
      "Processing videos\\veriff10.mp4...\n",
      "Found 2 unique persons in videos\\veriff10.mp4\n",
      "\n",
      "Processing videos\\veriff11.mp4...\n",
      "Found 1 unique persons in videos\\veriff11.mp4\n",
      "\n",
      "Processing videos\\veriff12.mp4...\n",
      "Found 7 unique persons in videos\\veriff12.mp4\n",
      "\n",
      "Processing videos\\veriff14.mp4...\n",
      "Found 1 unique persons in videos\\veriff14.mp4\n",
      "\n",
      "Processing videos\\veriff16.mp4...\n",
      "Found 2 unique persons in videos\\veriff16.mp4\n",
      "\n",
      "Processing videos\\veriff17.mp4...\n",
      "Found 11 unique persons in videos\\veriff17.mp4\n",
      "\n",
      "Processing videos\\veriff18.mp4...\n",
      "Found 8 unique persons in videos\\veriff18.mp4\n",
      "\n",
      "Processing videos\\veriff19.mp4...\n",
      "Found 1 unique persons in videos\\veriff19.mp4\n",
      "\n",
      "Processing videos\\veriff2.mp4...\n",
      "Found 2 unique persons in videos\\veriff2.mp4\n",
      "\n",
      "Processing videos\\veriff3.mp4...\n",
      "Found 1 unique persons in videos\\veriff3.mp4\n",
      "\n",
      "Processing videos\\veriff4.mp4...\n",
      "Found 96 unique persons in videos\\veriff4.mp4\n",
      "\n",
      "Processing videos\\veriff5.mp4...\n",
      "Found 11 unique persons in videos\\veriff5.mp4\n",
      "\n",
      "Processing videos\\veriff6.mp4...\n",
      "Found 1 unique persons in videos\\veriff6.mp4\n",
      "\n",
      "Processing videos\\veriff7.mp4...\n",
      "Found 1 unique persons in videos\\veriff7.mp4\n",
      "\n",
      "Processing videos\\veriff8.mp4...\n",
      "Found 1 unique persons in videos\\veriff8.mp4\n",
      "\n",
      "Processing videos\\veriff9.mp4...\n",
      "Found 1 unique persons in videos\\veriff9.mp4\n",
      "\n",
      "Processed 17 unique videos with coercion detection results.\n",
      "Coercion detection accuracy: 70.59%\n",
      "Testing with confidence threshold: 0.65\n",
      "Processing videos\\veriff1.mp4...\n",
      "Found 1 unique persons in videos\\veriff1.mp4\n",
      "\n",
      "Processing videos\\veriff10.mp4...\n",
      "Found 2 unique persons in videos\\veriff10.mp4\n",
      "\n",
      "Processing videos\\veriff11.mp4...\n",
      "Found 1 unique persons in videos\\veriff11.mp4\n",
      "\n",
      "Processing videos\\veriff12.mp4...\n",
      "Found 5 unique persons in videos\\veriff12.mp4\n",
      "\n",
      "Processing videos\\veriff14.mp4...\n",
      "Found 2 unique persons in videos\\veriff14.mp4\n",
      "\n",
      "Processing videos\\veriff16.mp4...\n",
      "Found 2 unique persons in videos\\veriff16.mp4\n",
      "\n",
      "Processing videos\\veriff17.mp4...\n",
      "Found 11 unique persons in videos\\veriff17.mp4\n",
      "\n",
      "Processing videos\\veriff18.mp4...\n",
      "Found 7 unique persons in videos\\veriff18.mp4\n",
      "\n",
      "Processing videos\\veriff19.mp4...\n",
      "Found 1 unique persons in videos\\veriff19.mp4\n",
      "\n",
      "Processing videos\\veriff2.mp4...\n",
      "Found 2 unique persons in videos\\veriff2.mp4\n",
      "\n",
      "Processing videos\\veriff3.mp4...\n",
      "Found 1 unique persons in videos\\veriff3.mp4\n",
      "\n",
      "Processing videos\\veriff4.mp4...\n",
      "Found 93 unique persons in videos\\veriff4.mp4\n",
      "\n",
      "Processing videos\\veriff5.mp4...\n",
      "Found 11 unique persons in videos\\veriff5.mp4\n",
      "\n",
      "Processing videos\\veriff6.mp4...\n",
      "Found 1 unique persons in videos\\veriff6.mp4\n",
      "\n",
      "Processing videos\\veriff7.mp4...\n",
      "Found 2 unique persons in videos\\veriff7.mp4\n",
      "\n",
      "Processing videos\\veriff8.mp4...\n",
      "Found 1 unique persons in videos\\veriff8.mp4\n",
      "\n",
      "Processing videos\\veriff9.mp4...\n",
      "Found 1 unique persons in videos\\veriff9.mp4\n",
      "\n",
      "Processed 17 unique videos with coercion detection results.\n",
      "Coercion detection accuracy: 58.82%\n",
      "\n",
      "Confidence Threshold: 0.3\n",
      "Coercion Detection Accuracy: 52.94%\n",
      "\n",
      "Confidence Threshold: 0.45\n",
      "Coercion Detection Accuracy: 58.82%\n",
      "\n",
      "Confidence Threshold: 0.5\n",
      "Coercion Detection Accuracy: 58.82%\n",
      "\n",
      "Confidence Threshold: 0.55\n",
      "Coercion Detection Accuracy: 58.82%\n",
      "\n",
      "Confidence Threshold: 0.6\n",
      "Coercion Detection Accuracy: 70.59%\n",
      "\n",
      "Confidence Threshold: 0.65\n",
      "Coercion Detection Accuracy: 58.82%\n"
     ]
    }
   ],
   "source": [
    "video_paths = glob.glob(\"videos/veriff*.mp4\")\n",
    "\n",
    "different_confidences_result = test_with_confidence_thresholds(video_paths, model, thresholds=[0.3, 0.45, 0.5, 0.55, 0.6, 0.65])\n",
    "# different_confidences_result = test_with_confidence_thresholds(video_paths, model, thresholds=[0.3])\n",
    "\n",
    "for threshold, (coercion_results, accuracy) in different_confidences_result.items():\n",
    "    print(f\"\\nConfidence Threshold: {threshold}\")\n",
    "    print(f\"Coercion Detection Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df565",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Visualizing confusion matrices and looking at prediction accuracy metrics (accuracy, precision, recall, F1-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aa44865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce995be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(coercion_results, threshold):\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(coercion_results['label'], coercion_results['coercion_detected'])\n",
    "\n",
    "    # Plot with better formatting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm,\n",
    "        display_labels=['No Coercion', 'Coercion']\n",
    "    )\n",
    "    disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "    plt.title(f'Coercion Detection Confusion Matrix (Threshold: {threshold})')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate and display metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62b635d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "---- Confidence Threshold: 0.3 ----\n",
      "Coercion Detection Accuracy: 52.94%\n",
      "     video  coercion_detected  label  match\n",
      "0  veriff1                  1      0  False\n",
      "1  veriff2                  0      1  False\n",
      "2  veriff3                  0      0   True\n",
      "3  veriff4                  1      1   True\n",
      "4  veriff5                  1      0  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n",
      "Precision: 0.46\n",
      "Recall: 0.86\n",
      "F1 Score: 0.60\n",
      "\n",
      "\n",
      "\n",
      "---- Confidence Threshold: 0.45 ----\n",
      "Coercion Detection Accuracy: 58.82%\n",
      "     video  coercion_detected  label  match\n",
      "0  veriff1                  1      0  False\n",
      "1  veriff2                  0      1  False\n",
      "2  veriff3                  0      0   True\n",
      "3  veriff4                  1      1   True\n",
      "4  veriff5                  1      0  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 Score: 0.59\n",
      "\n",
      "\n",
      "\n",
      "---- Confidence Threshold: 0.5 ----\n",
      "Coercion Detection Accuracy: 58.82%\n",
      "     video  coercion_detected  label  match\n",
      "0  veriff1                  1      0  False\n",
      "1  veriff2                  0      1  False\n",
      "2  veriff3                  0      0   True\n",
      "3  veriff4                  1      1   True\n",
      "4  veriff5                  1      0  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 Score: 0.59\n",
      "\n",
      "\n",
      "\n",
      "---- Confidence Threshold: 0.55 ----\n",
      "Coercion Detection Accuracy: 58.82%\n",
      "     video  coercion_detected  label  match\n",
      "0  veriff1                  1      0  False\n",
      "1  veriff2                  0      1  False\n",
      "2  veriff3                  0      0   True\n",
      "3  veriff4                  1      1   True\n",
      "4  veriff5                  1      0  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 Score: 0.59\n",
      "\n",
      "\n",
      "\n",
      "---- Confidence Threshold: 0.6 ----\n",
      "Coercion Detection Accuracy: 70.59%\n",
      "     video  coercion_detected  label  match\n",
      "0  veriff1                  0      0   True\n",
      "1  veriff2                  1      1   True\n",
      "2  veriff3                  0      0   True\n",
      "3  veriff4                  1      1   True\n",
      "4  veriff5                  1      0  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAHWCAYAAAB5ZP2xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABH2ElEQVR4nO3dCbxMdf/A8e9cy7XvhCzZl+xbiyylUE8SSpYiVE8SypqnRBSiQiqkQtKiREWRpPSUfXvITuUm0mK7lms7/9f3pzP/mTH33rnmzJ177v28e53cmTlzzm/OnOU7399yPJZlWQIAAJDBxUS7AAAAAGkBQREAAABBEQAAwEUERQAAAARFAAAAFxEUAQAAEBQBAABcRFAEAABAUAQAAHARQRHCctVVV8n9998f7WKkOxl5u+7atUuaN28uefPmFY/HI/Pnz3d0+T///LNZ7owZMxxdrps1bdrUTE6Ki4uTbNmyyffff5/i9w4fPtx8R3/++aekBZEoT6jb/JtvvjHr1n/TsilTpkipUqUkISFB3IygKI3Ys2eP/Pvf/5ayZcuaE0mePHmkYcOGMnHiRDl16lS0i5fm6AVNTxT2pNusePHi0qJFC3n55Zfl+PHjl73srVu3mpOgXjwj6YcffjDrOXLkiKQ10dwfu3btKps3b5bnnntOZs2aJfXq1ZP0QgNd3V91ewbbjhoQ2vv0Cy+8kOLl//bbb2af2rhxo0TbiBEj5JprrjH7jX1hD2WC8/bv3y/t27eXfPnymX2vdevWsnfv3pDff+bMGRk1apRUrlzZnA+uuOIK+de//iW//vqr376t802dOlXcLHO0CwCRhQsXyt133y2xsbHSpUsXqVatmtm5/vvf/8rAgQPlxx9/lNdff13Soh07dkhMTExUT7xlypSRs2fPysGDB83J97HHHpOXXnpJPv30U6lRo8ZlBUXPPPOM+RWnGZtIBkW6Hj2Z6MkqrWzXaO6PGiisWLFCnnzySXn00Ucjso7SpUub9WTJkkWiIXPmzHLy5En57LPPzIXK1+zZs81F5/Tp05e1bA2KdJ/S/bZWrVohv+/LL78UJ/3xxx8yc+ZMM6kqVaqYANfXkCFDJFeuXOa7RuTEx8fLjTfeKEePHpX//Oc/Zr8fP368NGnSxATPBQsWTPL9Z8+eNQGQnq8efPBBc049fPiwrFq1yiyzRIkSZj7db/UHjZ57e/fu7doAl6Aoyn766Sfp0KGDOVF//fXXUqxYMe9rvXr1kt27d5uLVGo6ceKE5MyZM6R59cIZTbfeeqtfJkFPtLodb7/9drnjjjtk27Ztkj17dnGbaG3XaO+PejFVgUGik+zMYjS/W82evPfee5cERe+++665AM2dOzdVyqLBWY4cOSRr1qyOLvedd94xwV+rVq3MY80s3HvvvX7zjBkzRgoVKnTJ8+G6cOGCCeKj+R2nJa+99prJQK5evVrq16/vPW/qj50XX3zRZICSMn78ePn222/Nj6IGDRokOa/uz2PHjpVly5bJTTfdJK5kIaoefvhhS7+G77//PqT5z549a40YMcIqW7aslTVrVqt06dLWkCFDrNOnT18y7+eff27dcMMNVo4cOaxcuXJZt912m7Vlyxa/ebp27WrlzJnT2r17t3Xrrbea+Vq3bm1eO3/+vDVhwgSrWrVqVmxsrFWoUCGrRYsW1po1a7zv1/XrMnzt2bPHuuuuu6z8+fNb2bNnt6655hprwYIFfvMsW7bMfO4PPvjAevbZZ60rr7zSrOOmm26ydu3alex2mD59unm/b1l8jRo1yrz++uuv+z2/bds2q127dqZsur66detan3zyySXLDZy0vCnZrva67r77brPdsmXLZlWsWNH6z3/+Y14bNmxY0PX89NNPUd2ukdof9fl//etf1nfffWfVr1/flKlMmTLWzJkzvfME2yb6PqXbwv7bl/0eX19++aXVsGFDK2/evGbf1u2uZbLpNtb36Hfta+nSpd7vVd97xx13WFu3bg26Pt2WWiadL0+ePNb9999vnThxItntZR9vM2bMMNvg8OHD3tdWr15tlj137lzz77hx47yv/fXXX1b//v3Nsajvz507t9WyZUtr48aNl3z3gZP9OZs0aWJdffXV1tq1a61GjRqZfahv377e13SydenSxZQv8PM3b97cypcvn7V///4kP2fjxo2tpk2bJjmPlsV3nZe7nXW+Xr16We+8845VtWpVK3PmzNa8efPMa7/++qvVrVs3q0iRImb/1NfffPPNS9b38ssvm9d0m+jn0/PC7NmzL6s8oR4TgdtcxcXFmfOv7oOFCxe2HnvsMWvRokWXnIN0nXp++eOPP6zk6PGmUyD9LsuVK5fke8+fP28VL17cat++vfezJbefFyhQwOrTp4/lVgRFUaYXLT14QqUHpB4genF89dVXzclLH995551+87399tuWx+MxJ85JkyZZzz//vHXVVVeZA96+8NrL05OfHhz695QpU8x7lR7wumwNljQ4euGFF8wBq8uzBV68Dx48aF1xxRXmpP3kk09aL730klWzZk0rJibG+vjjjy85gdeuXducgMaPH28NHz7cnAwaNGgQdlCkJxd7O9k0cNGTmZ78dHu88sor5uSt28kumwYeekDrezWAmTVrlpn0c6Vku27atMmcNAsWLGhOiFOnTrUGDRpkVa9e3ft6x44dzXr0s9vriY+Pj+p2jdT+qJ+nUqVK5jPodtVtX6dOHbMt7YBSt4mWV9+v20a3h31xCzUo0mXphahevXrWxIkTzf48YMAA8z0nFRQtWbLEXEw1gBo7dqz1zDPPmGBWA1Df79Ven27ftm3bWq+99pr1wAMPmOf0+w1le2lQc+zYMRMo+16g9QJYuXJlb/l8gyLdz/UYfeKJJ8y+pBdd/a50f7YDFN1H9Hl970MPPeTdp3SfVnoBLlq0qLnY9u7d2yxn/vz5QS/QGqyVKFHCXEzPnTtnntNtqcvWZSblzJkzJrjo169f2EFRKNtZn6tSpYr5XPq96X64YcMGsz30M5QsWdJsl8mTJ5tA1z7mbPrDyd6HdZvoftOjRw+/C3tKyhPqMRG4zU+ePGn2P90vdJl6ztVjuEaNGpcERfZxruVKLqjR83vPnj0vee2pp54yy9B9MTGbN2828+gPrAcffNAcW/pYz2Nff/110PfcfPPNptxuRVAURUePHjU7mJ2ZSY7+KtT59WD0pSd9fd7eSY8fP24u0roT+9KThJ5EfZ+3D2A92frSZenzwSL+CxcueP8OvHjriV3fpxkBm5ZHswIaPOhB6ntQ68ksISHBO6+ekPR5PRjDCYqUflY9idmaNWtmDmbfX2z6Wa6//nqrQoUK3uc+/PDDS05CKd2uehHWAOaXX35JdNvpRc83O+QrGts1Uvuj/Xn0ueXLl3ufO3TokDlhawbEFiwgSElQZAdVSf2CDhYU1apVy2QTNCNj0yBNg069qAWur3v37n7LbNOmjQmAQw2KlF40dZ9U+v1pwKIX9WDbQPdZ+zv2/Ry6/fSCb9PjIVgWTOkFWF/T4CbYa4EByuLFi70XxL1795qsaOCFPRjNOuv7fH88XW5QFMp21vn0e/rxxx/9ntfAplixYtaff/7p93yHDh3M8apBiNL9XcuSlFDLk5JjInCbaxCk88yZM8f7nGZlypcvf9lBkR4HOp/vPmLTgE1f2759e6Lv//jjj808+hn1HKn7lU76twZIeowE0oBcg2K3ovdZFB07dsz8mzt37pDm//zzz82//fr183u+f//+5l+7rceSJUtMj6aOHTuaLqT2lClTJtMbROt7A/Xs2dPvsbZp0LYXw4YNu2TepBrQaRm13vmGG27wPqeNKR966CHTm0sbMfvq1q2bX3uGRo0amX9T0jMiMbpeuxfa33//bdrIaJ23Pmdvk7/++sv0WNM6d+2hkZRQt6u2i1m+fLl0797ddFH1dbmND1Nju0Zqf7RVrVrVWw5VuHBhqVSpkiPftc1ui/TJJ5+YtiWhOHDggGlwqg3eCxQo4H1eG5Tecsst3s/p6+GHH/Z7rJ9L9yV7G4aiU6dOpmOAdhDQfVP/1ecSa4dkN7w/f/68WZd+/7r91q9fH/I6dTm6b4RCh0XQHojamaFt27amjU4oPYu0bCp//vwSrlC3szYa1v3LprGSnsO0TZP+7Xu86vGuDYTt7ab7jPaiWrNmTdjlSekx4Uvfq2347rrrLu9z2t5Lj/FA2glEP5f2NEyK3cMxWBtFu81VUr1J4+Pjzb96zly6dKk5RnT66quvzPq1/VAg/d51mdpezY0IiqJIu0aqULuP//LLL+bEWL58eb/nixYtag5sfV3pBV5pQze98PhO2svk0KFDfu/XBpF2DwLfLtnaxd33IhFqGfVEHUh7n9iv+woMGuwTqfZuCJce0PYFXhsI60E8dOjQS7aJHfgFbpdAoW5X+yKvDRmdkhrbNVL7Y2JlssvlxHdtu+eee0wj5gceeMA07tVG43PmzEkyQLLLmdj21Qupdj5wer+97bbbzP75wQcfmF5n2gg2cFvatPza4LVChQrmAqcNlHW/+9///mcu8KG68sorU9SoWocF0HOABo061EWRIkVCfu/FJE54Qt3O2gPVl/4w0R8w2ksy8Fi1g0L7eB08eLAJMPVHh25f7VCQ2NhKyZUnpceEL31N3xf4wynYfhkqu5NJsLGD7B6OSXVEyf7Pa3pMlSxZ0m876A807ZGW2PdO7zOkmF6ENPDYsmVLit6X3M5mXwC0C6wejIE0CErsV2hq0yxLJE6o+stPLxb2ycneJgMGDDC/FINJ7IJ0uds1mi5nu0ZqfwynTMmtQ7MmgSdxzdJp1k5/lS9atMgEHRrIauCaWBmisd/qcacZGO22roF0Ur/6tYeQBvSafRw5cqQJVPSY1eEnQs2IqZT2xNywYYM3eNCxozRLmhy7i7cTwW6o2znwc9nbRHu2aTfxYOzhOjTw1SEwFixYYPYXzTBpj62nn37aDG9wOeVJKwGB7ie6n2k2NJD9nB7ziSn+z2v6AyOQBsi6fwTS710zXG7s9avSzlk8g9Ku4/prRsdmue6665KcV7tJ68GuGQs7Q6B+//1386tIX1flypXz7rQ333zzZZVLl7F48WJT7ZSSbJGWQU8wgbZv3+59PTXYY6LYAZAOQqh0jI7ktkliJ7RQt6u9ruSCi5ScOFNru0Zif3SC/iIPNshlsF/eGiw0a9bMTDpmigYUOhaOBkrBvje7nIltX83KhDpERUppddlbb71lyqxZrcR89NFHZqyZN9980+953SZavkhcjDU7plkVrZa6/vrrTVVJmzZtvN26E6NZBL0g6vAO0aIZIc3CadAcyjlQv1/NMuqk3fk1WNXBQ3WIj5R07Q/nmNDX9JyhAZbv9xhsvwyV7lfVq1eXtWvXXvKajjOk56qkqsurV69uzpnBmhbomFi6nQPp9+772d2G6rMoGzRokDkgNd2vB04grcbSUYTtdLuaMGGC3zx64lc6vokdCOivfr0Y6MBbiY0Fk5R27dqZgzPwl1Jyv4a1jDoehl5UfU+ueqHVAeV86/0jRdtn6K9pTal37tzZG8hoPby2iQj2q8l3m9gXwMCLcKjbVU8UjRs3Nhe7ffv2JbrtEltPNLdrJPZHJ2hAqpk/rS6y6fc4b948v/k0iA9kD2KY2O0HtB2HzqMZG9/vQi9Qml2yP2ckaKCj++orr7wSNPvom6EIPO4+/PDDSy5WKdmnkqPVSrr/6nbR71T3M826JHcbB72I6thhwS7EqUW3l57DNOsT7MeJ7/Fut4GyafWiHk+6vYMd50kJ55jQ92qgoQGwTdvlBBsoVZ/XgD2U245oGyVtL+X7fWigpedJHaTV1/bt2/3OWRowabm0msz+AaZ0/Dd9TtvcBdK2WhpEuxWZoijTk70O2Ka/UDS69h1BWHc6PfHZ98CqWbOmOSnpQaInPW1cqBdKPWndeeed5gSr9MI9efJkue+++6ROnTrmF6heqHVn1yoFrR/Wk3BSdFn6fm1HoL96WrZsaX4Bfffdd+a1xEYbfuKJJ8ygdDo4WJ8+fUyWScunvx70BOV0Nd0XX3xhDtZz586Zi7ge6NogWn916YjWvr/yXn31VVMPrr9+dGRW/ZWk79FAQ6vbNm3aZObTC6SeVJ9//nlzIdb0s1a/aGAV6nbV7abr0vm0oaQGaNogWuezb8FQt25d869mMXRZejHRhqHBshKptV0jsT86QbePXqQ1U6GfXy8K+l1UrFjRr6GxNgrW6jO9+Og+oFU/WhWibeZ8G6kHGjdunNm2mh3r0aOHaSg6adIkc/+15BqzhkO/t6eeeiqkDJ5+Ns3c6AVHq7K0HZKdlfT9/rTtit6HSi9oui9pJ4DANjfJ0eNIt5u2t9N9WE2fPt38sNBqvGANbH3pbSR0v9YGyHZbtdSmg0NqdlA/vx7vGuho0Kz7izYUtgNobVCuAakev1pNpBd8PY51Hwq104EtnGNCy6jr1WNu3bp1JljXjLdWRQXSZeqy9PtJbv985JFHZNq0aebzaPMBPc9okKaf1W4AbqtSpYops+991vRHoDay1nOgHnv2+U3PQTpCti8tt25X/f5dK9rd33DRzp07TZdu7V6tXR21O7cOQKfdWn27kOvgWdptV7tiZ8mSxYzBkdjgjdptUwdb1O6nOvaFjnOiYw/p4G3BuggH0vFJtFuwjp2iZdJxQHTMonXr1nnnSWqQQe2+ruvV8XESG2RQu7/7SmxgvUCBgyxq+bRL8y233GK6nyc29oaWTbtY67y6/XSsl9tvv9366KOP/OabNm2aGa8nU6ZMQbvDJrdd7TFztMuuvR10nJ6hQ4f6zTNy5EhTBu1SHOrgjZHcrpHaH+3BGwMFdktOrEu+PSijDl6o5dFtqYP1BXbJ1wEYtYu1Djin8+m/OuaRfp7ktsVXX31lPqN2J9Yxplq1apXo4I2BXf7t/THY8Aq+kjrektoGuj116ALtYq7l03KuWLEiaFd6HYzUHsQw2OCNwfguR48d/b50HCn9fn09/vjjZl/VdSfl999/N+tPakyjULrkh7Kd7cEbEyuHvqb7pe6fetzrMAi+g7rq2EQ6hIZ2O7fHbBs4cKAZouJyyhPqMRHsu9MhPHQsJR1XTMfJ0sE1gw3eGGqXfN9x2/Tcofu1Dq2g57xgg7mKSNDvRM/5Ov6QPXCoHmO+x5Rt8ODBVqlSpfyGHnEbj/4v2oEZACB90Yzbzp07TXYZ6V9CQoKpYtWsdt++fcWtaFMEAHCcVu1oW5bEurcjfZk+fbqpmgscy8ltyBQBAACQKQIAALiIoAgAALietmnSMZ4CJx2lPFR0yQcAAK6nbdh8R7nXMap0LKXA8ZiSQpsiAACQ7uhtcPT2LTrWXqijvZMpykB08EUdMVUHJEsr9+YBAESe5j/0Zs96P7NI3+vy9OnTZsBXJwTe9kTpgLo6JUXX/84770i/fv1SdL0jKMpANCDyvdMxACBjiYuLMyO8RzIgyp67oMi5k44sL1euXBIfH+/3XCgjec+fP9+MKm6PwB8qgqIMxB6yPmvVruLJlDXaxQFS3VfvDYt2EYCoOBF/XFpeWyXFty5JKZMhOndSYqt2FQn3OnP+jMRvnWkCOd/bxSSXJVJ682S9dY9mxlKCoCgDsVOIGhARFCEjypU7OvfhAtKKVGs6kTlb2NcZy3Oxmk8DopTcQ++XX34x97f7+OOPU7xOgiIAAOAsjb3CDcA8lz+6tt7AW2+Cm1KMUwQAANJNhyINirp27SqZM6c870OmCAAAOEurvv6p/gprGSmk1Wb79u2T7t27X9YqCYoAAICztOos7OqzlL+/efPmphv/5aL6DAAAgEwRAABIL9Vn4SIoAgAA6aL6LFxUnwEAAJApAgAAzotxoPqL6jMAAOB2HqrPAAAAXItMEQAAcBa9zwAAAITqMwAAADcjUwQAAJxF9RkAAIBQfQYAAOBmZIoAAICzqD4DAACQf6rPwg2KqD4DAACICjJFAADAWTGei1O4y0hlBEUAAMBZLm1TRPUZAAAAmSIAAOA4jzvHKSIoAgAAzqL6DAAAwL3IFAEAAGdRfQYAACBUnwEAALgZmSIAAOAsqs8AAACE6jMAAAA3I1MEAACcRfUZAACAcqD6LAqVWVSfAQAAkCkCAACO81B9BgAAIBeDohjXBUVUnwEAAJApAgAAjvO4c5wigiIAAOAsl7YpovoMAACATBEAAHCch+ozAAAAofoMAADAxcgUAQAAZ1F9BgAAIFSfAQAAuBmZIgAA4CiPx2OmMBciqY2gCAAAOMqtQRHVZwAAAGSKAACA4zz/TOEuI5URFAEAAEdRfQYAAOBiZIoAAICj3JopIigCAACOcmtQRPUZAAAAmSIAAOA0j0szRQRFAADAWS7tkk/1GQAAAJkiAADgNA/VZwAAAGLimfCDIkl1VJ8BAACQKQIAAE7z6H9hV39RfQYAAFzO49I2RVSfAQAAkCkCAACO87hznCKCIgAA4CwHqs8sqs8AAACig0wRAABIcw2tw++9lnIERQAAwFFuDYqoPgMAAOnC/v375d5775WCBQtK9uzZpXr16rJ27dqQ30+mCAAAuL732eHDh6Vhw4Zy4403yhdffCGFCxeWXbt2Sf78+UNeBkERAABwffXZ888/LyVLlpTp06d7nytTpkyKlkH1GQAASLOOHTvmNyUkJASd79NPP5V69erJ3XffLUWKFJHatWvLtGnTUrQugiIAABCRTFG4k9LsT968eb3T6NGjg65z7969MnnyZKlQoYIsXrxYevbsKX369JGZM2eGXG6qzwAAQJqtPouLi5M8efJ4n4+NjQ06/4ULF0ymaNSoUeaxZoq2bNkiU6ZMka5du4a0TjJFAAAgzdKAyHdKLCgqVqyYVK1a1e+5KlWqyL59+0JeF5kiAADg+obW2vNsx44dfs/t3LlTSpcuHfIyyBQBAIDIdMkPd0qBxx9/XFauXGmqz3bv3i3vvvuuvP7669KrV6+Ql0FQBAAAXK9+/foyb948ee+996RatWoycuRImTBhgnTu3DnkZVB9BgAA0sVtPm6//XYzXS6CIgAA4CjufQYAAOBiZIoAAICj3JopIigCAACuvyGsE6g+AwAAIFMEAACc5qH6DECgTZ88I6WKF7zk+Tc+XC4Dx86JSpmA1PTxFyvl4y9WyYFDh83jsqWKSPd7msl1dStFu2iIIA9BEVLi/vvvlyNHjsj8+fOjXRRE0E1dx0mmTP9/YFcpV1zmv9pb5n+1IarlAlJL4YJ55ZEuLaRk8UJiWZZ8/vV6GTRqlswc31vKlroi2sUD0k6bIg0MNBIcM2aM3/MaKDgRIZ45c0bGjh0rNWvWlBw5ckihQoXMvVGmT58uZ8+elWiaOHGizJgxI6plQOT9dSReDv113Du1uKGa7I37Q75fvyvaRQNSRaMGVeT6epVNUFTqysLy8H0tJHu2rLJlR+g36YT7ePQ/T5hTFFpaR72hdbZs2eT555+Xw4cvpladogFRixYtTMD10EMPyQ8//CCrV68290CZNGmS/Pjjj46uL3DdycmbN6/ky5cvYmVA2pMlcyZpf2t9mf3pimgXBYiK8+cvyJLlm+T06TNSvVKpaBcHEeQJNyByoPrNlUHRzTffLEWLFpXRo0cnOd/cuXPl6quvltjYWLnqqqvkxRdfTHJ+vd/J8uXLZenSpSYQqlWrlpQtW1Y6deokq1atkgoVKpj5EhISpE+fPlKkSBEToN1www2yZs0av2Vt2bJFbr31VsmVK5dcccUVct9998mff/7pfb1p06by6KOPymOPPWayURqMKQ28dLjxPHnySO7cuaVRo0ayZ88eb5bszjvv9C4juXJ88803ZgfRz1OvXj2T+br++usvuSMw0q5/Na0heXNll3cXrIp2UYBUtfvng3LTPcOkyV1DZeyU+TJmyL1ShqozpEFRD4oyZcpk7mir2Ztff/016Dzr1q2T9u3bS4cOHWTz5s0yfPhwGTp0aJLVT7NnzzYBV+3atS95LUuWLJIzZ07z96BBg0zANXPmTFm/fr2UL1/eBDV///23eV3b/dx0001mOWvXrpVFixbJ77//bsrjS9+fNWtW+f7772XKlCmyf/9+ady4sQnivv76a/MZunfvLufOnQta3uTKYXvyySdNQKhlyZw5s1lmYjTQOnbsmN+E6Ln3juvlqxVb5eCfR6NdFCBVlb6ykMyc0FveGPeItGl5jYyc+JH8tO/3aBcLkeRxaMpoQZFq06aNyeQMGzYs6OsvvfSSNGvWzARCFStWNFkWzcyMGzcu0WXu2rVLKleunOR6T5w4IZMnTzbL0UxQ1apVZdq0aZI9e3Z58803zTyvvPKKCYg0cNPl6d9vvfWWLFu2THbu3OldlmaetP1SpUqVzPTqq6+aKrL333/fZHa03N26dTOvXU45bM8995w0adLEzPPEE0+YasHTp08H/XyafdMy2FPJkiWT3B6InJJF80vTBpXk7fk/RLsoQKrLkiWzlCxWSCqXv1Ie6dJSyl9VVD5YwLGQnnmoPguPtivSLMm2bdsueU2f0wbSvvSxBj7nz58Pujzt5ZAcrcrSBte+y9YsUoMGDbzl2LRpkwmAtOrMnuxgy64KU3Xr1vVb9saNG011mS7PiXLYatSo4f27WLFi5t9Dhw4FXe6QIUPk6NGj3ikuLi7ZsiAyOrW6Tv44fFy+/D5ybdkAt9Dz89mzwbPmQDSlmS75WtWk1UV6IddMULg0M7N9+/awlxMfHy+tWrUyQVsgOyhRdnWcTbM8keAbZNlR9IULF4LOq1V3OiG69Hvq3OpaeX/hKtPQFMhIXnt7kRmTqGihfHLiVIJ8uXyjrN/yk0wY3i3aRUMEeRinKHzaU0yr0QKrmKpUqWLa6vjSxxr4aJukYLRB9X/+8x/ZsGHDJe2KNCujPcTKlSvnbQdUunRp72vawFkbTas6deqYtj7auFvb8IRKMzqa+dLlJZctCqUccC+tNitZrIC88+nKaBcFSHWHj56QERPmyF9/H5dcObNJudJFTUDUoNbFzi5Inzyei1O4y8jQQVH16tWlc+fO8vLLL/s9379/f6lfv76MHDlS7rnnHlmxYoVp6/Paa68luiwNJhYuXGjaIun7tDeX9gDTBsqa9dG2OhqA9ezZUwYOHCgFChSQUqVKmXZBJ0+elB49epjlaM81bd/TsWNH0xha59u9e7dpK/TGG28kGpRpmydtPK6NwzX7pW16Vq5caarEAoM+zTIlVw6417JV2yV//UejXQwgKp7s3S7aRQDcGRSpESNGyAcffOD3nGZr5syZI08//bQJcLTaSudLqppNq42WLFki48ePl6lTp8qAAQNMN3bNOmnX92rVqnmzU1r9pN3sjx8/bhpFL168WPLnz29eL168uMngDB48WJo3b256dGk2p2XLlhITk3iTrIIFC5peZxroaMNoDZ40CAtsG2VLrhwAALgrU+QJexmpzWOF0iIZ6YJ2ydeMVWz1B8WTKWu0iwOkuhWfJD0eGpBexR8/Jo2qlTCdbnTsvEhfZ8r2+Ugyxfq3tU2p8wknZO/Ld0W8zGmy9xkAAEA0pbnqMwAA4G4eep8BAACIa3ufUX0GAABApggAADgtJsZjpnBYYb7/chAUAQAAR1F9BgAA4GJkigAAgKPofQYAACBUnwEAALgamSIAAOAoqs8AAADEvUER1WcAAABkigAAgNM8Lm1oTVAEAAAc5REHqs+E6jMAAICoIFMEAAAcRfUZAACA0PsMAADA1cgUAQAAR1F9BgAAIFSfAQAAuBqZIgAA4CiqzwAAAITqMwAAAFcjUwQAAJzlQPVZFO7yQVAEAACcRfUZAACAi5EpAgAAjqL3GQAAgFB9BgAA4GpkigAAgKOoPgMAABCqzwAAAFyNTBEAAHCUWzNFBEUAAMBRbm1TRPUZAAAAmSIAAOA0D9VnAAAAQvUZAACAm5EpAgAAjqL6DAAAQEQ0nAm7+kxSH9VnAAAAZIoAAIDTYjweM4W7jNRGUAQAABxF7zMAAAAXI1MEAAAc5dbeZ2SKAACAo2I8zkwpMXz4cG8wZk+VK1dO0TLIFAEAgHTh6quvlq+++sr7OHPmlIU5BEUAAMBZpqF16g9UpEFQ0aJFL3uVVJ8BAICI9D4Ld1LHjh3zmxISEhJd765du6R48eJStmxZ6dy5s+zbty9F5SYoAgAAaVbJkiUlb9683mn06NFB57vmmmtkxowZsmjRIpk8ebL89NNP0qhRIzl+/HjI66L6DAAAOMrzz3/hLkPFxcVJnjx5vM/HxsYGnf/WW2/1/l2jRg0TJJUuXVrmzJkjPXr0CGmdBEUAAMBRl9N7LNgylAZEvkFRqPLlyycVK1aU3bt3h77OFK8FAAAgjYuPj5c9e/ZIsWLFQn5PSJmi//3vfyEvUFNWAAAg4/JEYfDGAQMGSKtWrUyV2W+//SbDhg2TTJkySceOHZ0NimrVqmUKZ1lW0Nft1/Tf8+fPh/4JAABAuuOJwr3Pfv31VxMA/fXXX1K4cGG54YYbZOXKleZvR4MibcENAACQVr3//vthLyOkoEhTUQAAAKGI8XjMFI5w339Z67ycN82aNUsaNmxoBkj65ZdfzHMTJkyQTz75xOnyAQCADDx4Y5oOinRApH79+sltt90mR44c8bYh0q5vGhgBAAC4UYqDokmTJsm0adPkySefNK26bfXq1ZPNmzc7XT4AAOAynoC71V/ulOaDIm10Xbt27Uue1xEmT5w44VS5AAAA0nZQVKZMGdm4ceMlz+u9RqpUqeJUuQAAgEt5XNqmKMW3+dD2RL169ZLTp0+bsYlWr14t7733nrlB2xtvvBGZUgIAANeIcWnvsxQHRQ888IBkz55dnnrqKTl58qR06tTJ9EKbOHGidOjQITKlBAAAiLDLuiFs586dzaRBkd5bpEiRIs6XDAAAuJLnnyncZbgiKFKHDh2SHTt2mL+1hXhKhtEGAADplycK9z6LSkPr48ePy3333WeqzJo0aWIm/fvee++Vo0ePRqaUAAAAaS0o0jZFq1atkoULF5rBG3VasGCBrF27Vv79739HppQAAMA1YjzOTGm++kwDoMWLF5u7z9patGhhBnRs2bKl0+UDAAAu48ko1WcFCxaUvHnzXvK8Ppc/f36nygUAAJC2gyLtiq9jFR08eND7nP49cOBAGTp0qNPlAwAALuRx2cCNIVef6W09fNNYu3btklKlSplJ7du3z9zm448//qBdEQAAGZzHpdVnIQVFd955Z+RLAgAAEEUhBUXDhg2LfEkAAEC6EONA7zFX9D4DAADIsNVnvs6fPy/jx4+XOXPmmLZEZ86c8Xv977//drJ8AAAAabP32TPPPCMvvfSS3HPPPWYEa+2J1rZtW4mJiZHhw4dHppQAAMB19z7zhDml+aBo9uzZZqDG/v37S+bMmaVjx47yxhtvyNNPPy0rV66MTCkBAIBrxHg8jkypXu6UvkHHJKpevbr5O1euXN77nd1+++3m1h8AAABulOKgqESJEnLgwAHzd7ly5eTLL780f69Zs8aMVQQAADI2T5gDN0ZrAMcUB0Vt2rSRpUuXmr979+5tRrGuUKGCdOnSRbp37x6JMgIAABf2PvOEOaX53mdjxozx/q2NrUuXLi0//PCDCYxatWrldPkAAADSZqYo0LXXXmt6oF1zzTUyatQoZ0oFAABcy5NRqs8So+2MuCEsAACIySi9zwAAANIjbvMBAAAc5UT1VzSqzwiKAACAo9L9vc+0MXVS/vjjDyfKg1Sw75sXJE+ePNEuBpDq2r2xOtpFAKLi7Kn4aBfBFUIOijZs2JDsPI0bNw63PAAAwOViHGi0HJOWg6Jly5ZFtiQAACBd8Li0+ozeZwAAADS0BgAATvN4dKyi8JeR2giKAACAo2IcCIrCff9lrTP1VwkAAJD2kCkCAACOylANrb/77ju599575brrrpP9+/eb52bNmiX//e9/nS4fAABwafVZTJhTqpc7pW+YO3eutGjRQrJnz27GLkpISDDPHz16VEaNGhWJMgIAAKS9oOjZZ5+VKVOmyLRp0yRLlize5xs2bCjr1693unwAAMCl9z7zhDml+TZFO3bsCDpydd68eeXIkSNOlQsAALhUjMdjpnCXkeYzRUWLFpXdu3df8ry2JypbtqxT5QIAAEjbQdGDDz4offv2lVWrVpmW4b/99pvMnj1bBgwYID179oxMKQEAgOvufRYT5pTmq8+eeOIJuXDhgjRr1kxOnjxpqtJiY2NNUNS7d+/IlBIAALiGx4E2Qa5oU6TZoSeffFIGDhxoqtHi4+OlatWqkitXrsiUEAAAIC0P3pg1a1YTDAEAAPiKEQcaWosn7QdFN954Y5KjTH799dfhlgkAALiYJ6NUn9WqVcvv8dmzZ2Xjxo2yZcsW6dq1q5NlAwAASLtB0fjx44M+P3z4cNO+CAAAZGwxDtymwxW3+UiM3gvtrbfecmpxAADApTwmKPKENXncHBStWLFCsmXL5tTiAAAA0nb1Wdu2bf0eW5YlBw4ckLVr18rQoUOdLBsAAHAhT0ZpaK33OPMVExMjlSpVkhEjRkjz5s2dLBsAAHChGJe2KUpRUHT+/Hnp1q2bVK9eXfLnzx+5UgEAAKTlNkWZMmUy2aAjR45ErkQAAMDVPA79l+YbWlerVk327t0bmdIAAIB0U30WE+aU6uVO6RueffZZc/PXBQsWmAbWx44d85sAAADcKOQ2RdqQun///nLbbbeZx3fccYff7T60F5o+1nZHAAAg44pJ7w2tn3nmGXn44Ydl2bJlkS0RAABwNY8ZfDG8qCbc90c0KNJMkGrSpEkkywMAABAVmdN61AYAANwlJr1Xn6mKFSsmGxj9/fff4ZYJAAC4mCcjjGit7YoCR7QGAABID1IUFHXo0EGKFCkSudIAAADXi/nnTvfhLiMcY8aMkSFDhkjfvn1lwoQJzgZFtCcCAABuaFO0Zs0amTp1qtSoUSNl60xp7zMAAIC0Kj4+Xjp37izTpk1L8X1aQw6KLly4QNUZAABI3j8NrcOZLvfWZ7169ZJ//etfcvPNN0e2TREAAEByYsRjpnDY7w+8hVhsbKyZgnn//fdl/fr1pvrs8tYJAACQRpUsWdL0fLen0aNHB50vLi7ONKqePXu2ZMuW7bLWRaYIAACk2XGKNNjJkyeP9/nEskTr1q2TQ4cOSZ06dbzP6f1Yly9fLq+88ookJCRIpkyZklwnQREAAEizvc80IPINihLTrFkz2bx5s99z3bp1k8qVK8vgwYOTDYgUQREAAHC93LlzS7Vq1fyey5kzpxQsWPCS5xNDUAQAANLd4I2Xg6AIAACky3ufffPNNyman95nAAAAZIoAAEBExinyODNOUWoiKAIAAOmy+iylqD4DAAAgUwQAACKRcYlxYBmpjaAIAAA4yuPxmCncZaQ2qs8AAADIFAEAAKd5/pnCXUZqIygCAACOcuuI1lSfAQAAkCkCAACR4BH3ISgCAACOYvBGAAAAFyNTBAAAHOXWcYoIigAAgKPcOqI11WcAAABkigAAgNM8VJ8BAACIa0e0pvoMAACATBEAAHCah+ozAAAAofcZAACAm5EpAgAAjqL6DAAAQOh9BgAA4GpkigAAgKO05ivc2q8o1J4RFAEAAGfFiMdM4S4jtVF9BgAAQKYIAAA4zUP1GQAAgIjnn//CXUZqo/oMAACATBEAAHCah+ozAAAAMVVf4fYeo/oMAAAgSsgUAQAAR1F9BgAAIO4Niqg+AwAAIFMEAACc5nHpOEUERQAAwFExnotTuMtIbVSfAQAAkCkCAABO81B9BgAAIPQ+AwAAcDMyRQAAwFGa5Am/+iz1ERQBAABH0fsMAADAxcgURclVV10ljz32mJmQfr00fbEsWLZJdv3yu2SLzSINapSV4Y+2lgpXXRHtogGpon2dK+WeOlf6Pbf/yCnp89HmqJUJkeeh91nadPDgQXnuuedk4cKFsn//filSpIjUqlXLBCPNmjWLWrnWrFkjOXPmjNr6kTp+WL9bHri7sdSuWlrOnT8vI1/7TNr2fkVWznlKcmaPjXbxgFSx7++T8swXO7yPz1+woloeRJ7Hpb3P0nVQ9PPPP0vDhg0lX758Mm7cOKlevbqcPXtWFi9eLL169ZLt27dHZL26jixZsiQ5T+HChSOybqQtH03q5ff4tWH3SoXmQ2TjtjhpWKd81MoFpKbzliVHTp2NdjGAjN2m6JFHHhGPxyOrV6+Wdu3aScWKFeXqq6+Wfv36ycqVK808+/btk9atW0uuXLkkT5480r59e/n999/9lvPJJ59InTp1JFu2bFK2bFl55pln5Ny5c97XdR2TJ0+WO+64w2R/NDOlPvvsM6lfv755X6FChaRNmzZ+1WcTJkzwPk6uHMOHDzcZrlmzZpn35s2bVzp06CDHjx+P6DaEs47Fnzb/5s+TI9pFAVJNsTzZZFrHWvJa+xrSt2lZKZQza7SLhFTpfSZhT6kt3QZFf//9tyxatMhkhIJVU2n26MKFCyYQ0Xm//fZbWbJkiezdu1fuuece73zfffeddOnSRfr27Stbt26VqVOnyowZM7yBj2/QokHP5s2bpXv37qa6Th/fdtttsmHDBlm6dKk0aNAgaFlDKYfas2ePzJ8/XxYsWGAmnXfMmDGObTNEln7PQ176SK6pWVaqli8e7eIAqWLXoXh5ZfleeXbxDnn9+1+kSO5Yefb2KpItS7q9/EA0uPBIjCfMiTZFztm9e7dYliWVK1dOdB4NVDSI+emnn6RkyZLmubfffttkk7TNj2Z5NCv0xBNPSNeuXc3rmikaOXKkDBo0SIYNG+ZdVqdOnaRbt27ex5rF0Unfb6tZs+Zll8O+qGpAljt3bvP4vvvuM+8NDNBsCQkJZrIdO3YsxK2HSBgwdo5s23NAvpj2eLSLAqSaDb8e9f79i5ySnX/Ey5QONaVhmQKydOefUS0bECjdhuoaECVn27ZtJgixAxFVtWpVk0XS19SmTZtkxIgRplrLnh588EE5cOCAnDx50vu+evXq+S1748aNITfkDqUcSqvN7IBIFStWTA4dOpTockePHm2q2ezJd/lIXQPHzpHF322Rzyb3kSuvyB/t4gBRc/LMeTlw9LQUzZMt2kVBBHlcWn2WbjNFFSpUMG19wm1MHR8fb7I9bdu2veQ1bStkC6yiy549uzgtsPG2fj7NHiVmyJAhpv2Ub6aIwCj1g/NB4z6Uhd9sks+m9JXSVxaKdpGAqMqWOUauyJ1NDp/6K9pFQSR5HIhqGLzROQUKFJAWLVrIq6++KidOnLjk9SNHjkiVKlUkLi7OTDZtN6SvaaZGaQPrHTt2SPny5S+ZYmIS33w1atQwVVuhCKUclyM2NtY02vadkLoGPD9H5nyxRqaNvF9y5cgmv/95zEynTp+JdtGAVNGlQUmpWjS3FM6VVSoVySWDbqkgFyxL/ruHoAhpT7rNFCkNiLRLvjZw1iowDVS015g2ZNbeYhp4aDf9zp07m55g+pr2WGvSpIm3Ouzpp5+W22+/XUqVKiV33XWXCYS0Sm3Lli3y7LPPJrpubW+k1WflypUzbYt02Z9//rkMHjz4knlvvvnmZMsBd3pr7nfm39sfnuj3/KtP3yudWl0bpVIBqadgzqzy+I3lJHe2zHLs9DnZdvC4DPl0q/kb6ZeHwRvTHm0UvX79etMQuX///qYdkI4PVLduXRMUafWTdrfv3bu3NG7c2AQ8LVu2lEmTJnmXodkm7emlQdXzzz9vqrC08fYDDzyQ5LqbNm0qH374oWmUrT3ENEuj6wgmlHLAnQ6veSXaRQCiavyyPdEuAqLB48Dgi1GoPvNYobRIRrqgbYq0wfXvfx2lKg0ZUrs3Vke7CEBUnD0VL0v6NZOjRyN7/j/2z3Vm6cZ9kit3eOuJP35MmtUqFfEyZ5hMEQAASH0ed7azJigCAAAOc2lUlG57nwEAAKQEmSIAAOAoep8BAADIxZ5n4fY+C7v32mWg+gwAAIBMEQAAcJrHne2sCYoAAIDDXBoVUX0GAABcT+9Uobfzsu/1ed1118kXX3yRomUQFAEAgIj0Pgv3v5QoUaKEua3WunXrZO3atXLTTTdJ69at5ccffwx5GVSfAQAA1/c+a9Wqld9jve+pZo9WrlwpV199dUjLICgCAADpyvnz581N2U+cOGGq0UJFUAQAANJsO2u9yayv2NhYMwWzefNmEwSdPn1acuXKJfPmzZOqVauGvE7aFAEAgMhEReFOIlKyZEnJmzevdxo9enSiq61UqZJs3LhRVq1aJT179pSuXbvK1q1bQy42mSIAAJBmxcXFmd5ktsSyRCpr1qxSvnx583fdunVlzZo1MnHiRJk6dWpI6yIoAgAAafbeZ3YX+8tx4cIFSUhICHl+giIAAOD63mdDhgyRW2+9VUqVKiXHjx+Xd999V7755htZvHhxyMsgKAIAAK536NAh6dKlixw4cMC0PdKBHDUguuWWW0JeBkERAABw/V0+3nzzzTDXSFAEAACc5uHeZwAAAK5FpggAAKTZ3mepiaAIAAC4vveZE6g+AwAAIFMEAACc5nFnO2uCIgAA4DCXRkVUnwEAAJApAgAATvPQ+wwAAEDofQYAAOBmZIoAAICjXNrOmqAIAAA4zKVREdVnAAAAZIoAAIDTPPQ+AwAAEFP1FXbvMarPAAAAooNMEQAAcJRL21kTFAEAAIe5NCqi+gwAAIBMEQAAcJqH3mcAAADCvc8AAADcjEwRAABwlEvbWRMUAQAAh7k0KqL6DAAAgEwRAABwmofeZwAAAHKx9izc3meS+qg+AwAAIFMEAACc5nFnO2uCIgAA4CwGbwQAAHAxMkUAAMBh7qxAIygCAACOovoMAADAxcgUAQAAR7mz8oygCAAAOMxD9RkAAIB7kSkCAACO4t5nAAAALm5URPUZAAAAmSIAAOA0jzsTRQRFAADAWfQ+AwAAcDEyRQAAwFH0PgMAAHBxoyKqzwAAAMgUAQAAp3ncmSgiKAIAAM6i9xkAAICLkSkCAAAOC7/3WTQq0AiKAACAo6g+AwAAcDGCIgAAAKrPAACA0zxUnwEAALgXmSIAAOAo7n0GAAAgVJ8BAAC4GpkiAADgKO59BgAA4OKoiOozAAAAMkUAAMBpHnqfAQAACL3PAAAA3IxMEQAAcJRL21mTKQIAAA7zODSlwOjRo6V+/fqSO3duKVKkiNx5552yY8eOFC2DoAgAALjet99+K7169ZKVK1fKkiVL5OzZs9K8eXM5ceJEyMug+gwAALi+99miRYv8Hs+YMcNkjNatWyeNGzcOaRkERQAAIN31Pjt69Kj5t0CBAiG/h6AoA7Esy/x7/NixaBcFiIqzp+KjXQQgKs6dPuF3HYi0Yw5cZ+xlBC4rNjbWTEm5cOGCPPbYY9KwYUOpVq1ayOskKMpAjh8/bv4tX6ZktIsCAIjSdSBv3rwRW37WrFmlaNGiUsGh60yuXLmkZEn/ZQ0bNkyGDx+e5Pu0bdGWLVvkv//9b4rW57FSK2xE1Gnk/Ntvv5mW+Z5ojIqVwemvHT244+LiJE+ePNEuDpCq2P+jSy/1GhAVL15cYmIi28fq9OnTcubMGcfKHXi9Si5T9Oijj8onn3wiy5cvlzJlyqRofWSKMhA9EEqUKBHtYmR4ekHgooCMiv0/eiKZIfKVLVs2M6U2DaB69+4t8+bNk2+++SbFAZEiKAIAAK6nVWbvvvuuyRJpjcjBgwe9wWD27NlDWgbVZ0AqVh/owak9IviljIyG/R+RllizkOnTp8v9998f0jLIFAGpROvAtYFgcr0mgPSI/R+R5kSOh0wRAAAAt/kAAAC4iKAIAACAoAhIH7QRod4RGkgPrrrqKpkwYUK0i4EMiKAI6Sow0N4HY8aM8Xt+/vz5jgxWqYORjR07VmrWrCk5cuSQQoUKmSHktWeD3o05miZOnGhufgikhHZZ1nFdypYtaxpA6+CKrVq1kqVLl0a1XGvWrJGHHnooqmVAxkTvM6QrOmDY888/L//+978lf/78ji1XA6IWLVrIpk2bZOTIkSYY0m7FK1eulBdeeEFq164ttWrVcmx9gevWofPTwqBsSD9+/vlnsx/ny5dPxo0bJ9WrVzfB/eLFi814L9u3b4/IenUdWbJkSXKewoULR2TdQHLIFCFdufnmm819d0aPHp3kfHPnzpWrr77a/DrWVP2LL76Y5Pyaytch4/UXtF4wNADSX9edOnWSVatWSYUKFcx8CQkJ0qdPHylSpIgJ0G644Qbzq9eX3o/n1ltvNff0ueKKK+S+++6TP//80/t606ZNzTD1ejNDzUZpMKZ+/PFHuf32200wpgOTNWrUSPbs2RO0+iy5cuhor5o9089Tr149k/m6/vrrZceOHSna3nCvRx55xOwDq1evlnbt2knFihXNMdGvXz8T7Kt9+/ZJ69atzb6q+1379u3l999/91uODpRXp04ds5/pMfHMM8/IuXPnvK/rOiZPnix33HGH5MyZU5577jnz/GeffSb169c379P9vE2bNolWnyVXDr0Plh6Ts2bNMu/VHwkdOnTw3u8RCBVBEdKVTJkyyahRo2TSpEny66+/Bp1n3bp15qSqJ83NmzebE+rQoUOTrH6aPXu2Cbg0IxRIf/XqyV4NGjTIBFwzZ86U9evXS/ny5U1Q8/fff5vXjxw5IjfddJNZztq1a2XRokXm5K7l8aXv1+zQ999/L1OmTJH9+/dL48aNTRD39ddfm8/QvXt3v4uPr+TKYXvyySdNQKhlyZw5s1km0j/dD3Tf0wDf3nd9afZI75WogYjO++2338qSJUtk7969cs8993jn++6776RLly7St29f2bp1q0ydOtUcR3bgY9NjTIMePd50H1u4cKF5fNttt8mGDRtMcN6gQYOgZQ2lHEp/IGhV+YIFC8yk8wZWpQPJ0nGKgPSga9euVuvWrc3f1157rdW9e3fz97x583QsLu98nTp1sm655Ra/9w4cONCqWrVqosvOnj271adPnyTXHx8fb2XJksWaPXu297kzZ85YxYsXt8aOHWsejxw50mrevLnf++Li4kz5duzYYR43adLEql27tt88Q4YMscqUKWOWl9xnD6Ucy5YtM+v86quvvPMsXLjQPHfq1KkkPyfcb9WqVea7/vjjjxOd58svv7QyZcpk7du3z/vcjz/+aN63evVq87hZs2bWqFGj/N43a9Ysq1ixYt7HOv9jjz3mN891111nde7cOdF1ly5d2ho/fnzI5Rg2bJiVI0cO69ixY37H9DXXXBPS9gBsZIqQLmm7Is2SbNu27ZLX9DltS+FLH+/atUvOnz8fdHmhjHGqv1S1vYTvsjWLpL+A7XJom6Rly5aZagB7qly5svf9trp16/ote+PGjaa6LLm2GKGWw1ajRg3v38WKFTP/Hjp0KNl1wN1C2Z91X9GG1zrZqlatarJIvvvziBEj/PbnBx98UA4cOCAnT570vk+raAP352bNmoVU1lDKobTaTKuVffdn9mWkFA2tkS5pVZNWFw0ZMiTke94kRdtbONHwND4+3vTu0aAtkB2UqMAqjVBvZphSvkGW3UNPqyuQvmkbOP2+w92ndX/WNkRt27a95DXfu6Snxv4c+INBPx/7MlKKTBHSLW1PoI05V6xY4fd8lSpVTFsdX/pYAx9tkxSMNqj+6quvTPuHQJqVOXHihJQrV87bDsj3NW3grL9slTZI1QbT+qtW2/n4TsHadvhmdLT9Rihd/0MpBzK2AgUKmB8Nr776qtl3A2nbNz1O4uLizGTTdkP6mu/+rI3zA/dlnWJiYpLcn0Pt9h9KOQCnEBQh3dIuxp07d5aXX37Z7/n+/fubE7J2rd+5c6epZnvllVdkwIABiS5Le4JpdZSm/PVCotUG2thzzpw5cu2115qqNw1qevbsKQMHDjSNWPXErVUJWo3Qo0cPsxxt2KoNRjt27GiCFK3q0i7Q3bp1S7TqTmlvNL3LuDYO10bRuj7taROst1go5QB0P9Z9TqtVtVG+7lNaHaXHy3XXXWc6FtjHkDbW115q2qi6SZMm3uqwp59+Wt5++22TLdJgX9///vvvy1NPPZXkuvXGsO+99575V9+jDbCDZU9VKOUAHONtXQS4nG9jY9tPP/1kZc2a1a+htfroo49Mw2ptkFyqVClr3LhxyS7/9OnT1ujRo63q1atb2bJlswoUKGA1bNjQmjFjhnX27FkzjzZS7t27t1WoUCErNjbWvG43BrXt3LnTatOmjZUvXz7TgLty5cqmIeqFCxe8Da379u17yfo3bdpkGmlrg9LcuXNbjRo1svbs2RP0sydXDruh9eHDh73PbdiwwTyn2wwZw2+//Wb16tXLNGzW4+TKK6+07rjjDrN/qF9++cU8zpkzp9nn7r77buvgwYN+y1i0aJF1/fXXm305T548VoMGDazXX3/d+7ruU9rZIdDcuXOtWrVqmfXqftq2bdugDa1DKYc2tK5Zs6bf8vX9uhwgJTz6P+dCLAAAAHei+gwAAICgCAAA4CKCIgAAAIIiAACAiwiKAAAACIoAAAAuIigCAAAgKAIAALiIoAhA1OlNe++8807v46ZNm5pbq6S2b775xtxIVO+rlVqfNa2WE8iICIoAJHrx1guvTnqDWb3J54gRI+TcuXMRX/fHH39s7k2XFgMEvZnvhAkTUmVdAFJX5lReHwAXadmypUyfPl0SEhLk888/Nze0zZIliwwZMuSSec+cOWOCJ6fu4g4AqY1MEYBExcbGStGiRaV06dLSs2dPc8fyTz/91K8a6LnnnpPixYtLpUqVzPNxcXHSvn17yZcvnwluWrduLT///LN3mXpn9n79+pnXCxYsKIMGDdK79fqtN7D6TIOywYMHS8mSJU2ZNGv15ptvmuXeeOONZp78+fObjJGWS124cEFGjx4tZcqUkezZs0vNmjXlo48+8luPBnoVK1Y0r+tyfMt5OfSz9ejRw7tO3SYTJ04MOq/eWb5w4cKSJ08eefjhh01QaQul7ACcR6YIQMj0Av3XX395Hy9dutRc1JcsWWIenz17Vlq0aCHXXXedfPfdd5I5c2Z59tlnTcbpf//7n8kkvfjiizJjxgx56623pEqVKubxvHnz5Kabbkp0vV26dJEVK1bIyy+/bAKEn376Sf78808TJM2dO1fatWsnO3bsMGXRMioNKt555x2ZMmWKVKhQQZYvXy733nuvCUSaNGligre2bdua7NdDDz0ka9eulf79+4e1fTSYKVGihHz44Ycm4Pvhhx/MsosVK2YCRd/tli1bNlP1p4FYt27dzPwaYIZSdgARYgFAEF27drVat25t/r5w4YK1ZMkSKzY21howYID39SuuuMJKSEjwvmfWrFlWpUqVzPw2fT179uzW4sWLzeNixYpZY8eO9b5+9uxZq0SJEt51qSZNmlh9+/Y1f+/YsUPTSGb9wSxbtsy8fvjwYe9zp0+ftnLkyGH98MMPfvP26NHD6tixo/l7yJAhVtWqVf1eHzx48CXLClS6dGlr/PjxVqh69epltWvXzvtYt1uBAgWsEydOeJ+bPHmylStXLuv8+fMhlT3YZwYQPjJFABK1YMECyZUrl8kAaRakU6dOMnz4cO/r1atX92tHtGnTJtm9e7fkzp3bbzmnT5+WPXv2yNGjR+XAgQNyzTXXeF/TbFK9evUuqUKzbdy4UTJlypSiDImW4eTJk3LLLbf4Pa9VVLVr1zZ/b9u2za8cSjNc4Xr11VdNFmzfvn1y6tQps85atWr5zaPZrhw5cvitNz4+3mSv9N/kyg4gMgiKACRK29lMnjzZBD7abkgDGF85c+b0e6wX9Lp168rs2bMvWZZW/VwOuzosJbQcauHChXLllVf6vaZtkiLl/ffflwEDBpgqQQ10NDgcN26crFq1Ks2XHQBBEYAkaNCjjZpDVadOHfnggw+kSJEipn1PMNq+RoOExo0bm8faxX/dunXmvcFoNkqzVN9++61p6B3IzlRpI2db1apVTQCh2ZrEMkzansluNG5buXKlhOP777+X66+/Xh555BHvc5ohC6QZNc0i2QGfrlczctpGShunJ1d2AJFB7zMAjuncubMUKlTI9DjThtbaIFobE/fp00d+/fVXM0/fvn1lzJgxMn/+fNm+fbsJIJIaY0jHBeratat0797dvMde5pw5c8zr2jNOe51pVd8ff/xhMi2aodGMzeOPPy4zZ840gcn69etl0qRJ5rHSHl+7du2SgQMHmkba7777rmkAHor9+/ebaj3f6fDhw6ZRtDbYXrx4sezcuVOGDh0qa9asueT9WhWmvdS2bt1qesANGzZMHn30UYmJiQmp7AAixIF2SQDSeUPrlLx+4MABq0uXLlahQoVMw+yyZctaDz74oHX06FFvw2ptRJ0nTx4rX758Vr9+/cz8iTW0VqdOnbIef/xx00g7a9asVvny5a233nrL+/qIESOsokWLWh6Px5RLaWPvCRMmmIbfWbJksQoXLmy1aNHC+vbbb73v++yzz8yytJyNGjUyywylobXOEzhpI3NtJH3//fdbefPmNZ+tZ8+e1hNPPGHVrFnzku329NNPWwULFjQNrHX76HttyZWdhtZAZHj0f5EKuAAAANyC6jMAAACCIgAAgIsIigAAAAiKAAAALiIoAgAAICgCAAC4iKAIAACAoAgAAOAigiIAAACCIgAAgIsIigAAAAiKAAAAxPg/jjywRdwOPbYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "Precision: 0.62\n",
      "Recall: 0.71\n",
      "F1 Score: 0.67\n",
      "\n",
      "\n",
      "\n",
      "---- Confidence Threshold: 0.65 ----\n",
      "Coercion Detection Accuracy: 58.82%\n",
      "     video  coercion_detected  label  match\n",
      "0  veriff1                  0      0   True\n",
      "1  veriff2                  1      1   True\n",
      "2  veriff3                  0      0   True\n",
      "3  veriff4                  1      1   True\n",
      "4  veriff5                  1      0  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n",
      "Precision: 0.50\n",
      "Recall: 0.71\n",
      "F1 Score: 0.59\n"
     ]
    }
   ],
   "source": [
    "for threshold, (coercion_results, accuracy) in different_confidences_result.items():\n",
    "    print(f\"\\n\\n\\n---- Confidence Threshold: {threshold} ----\")\n",
    "    print(f\"Coercion Detection Accuracy: {accuracy:.2f}%\")\n",
    "    print(coercion_results.head())\n",
    "    plot_confusion_matrix(coercion_results, threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acee30",
   "metadata": {},
   "source": [
    "Based on this quite limited dataset and analysis, I would go with either the confidence=0.3 for great recall (meaning I'd catch most coerced videos) or confidence=0.6 (giving the best F1-score and balance between recall and precision, meaning we wouldn't bother non-coerced videos with false positives that much) models. Considering that the real-life dataset might be imbalanced towards there being fewer coerced videos, I would go with a higher confidence threshold conf=0.6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a73f74",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37c0db",
   "metadata": {},
   "source": [
    "I built a proof-of-concept for a coercion detection system that uses object-detection and tracking ML models. I then also fine-tuned the confidence threshold for object (face) detection and visualized its prediction accuracy metrics. I finally settled on a YOLOv8 (conf=0.6) + Deep SORT system and built the entire app around that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coercion-check",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
